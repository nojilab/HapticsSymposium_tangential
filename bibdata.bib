@book{gescheider1985psychophysics,
  title={Psychophysics: method, theory, and application},
  author={Gescheider, G.A.},
  isbn={9780898593754},
  lccn={84013688},
  memo={https://books.google.co.jp/books?id=c\_VqAAAAMAAJ},
  year={1985},
  publisher={L. Erlbaum Associates}
}


@Article{Srinivasan1996,
author="Srinivasan, Mandayam A.
and LaMotte, Robert H.",
editor="Franz{\'e}n, O.
and Johansson, R.
and Terenius, L.",
title="Tactual discrimination of softness: abilities and mechanisms",
journal="Somesthesis and the Neurobiology of the Somatosensory Cortex",
year="1996",
publisher="Birkh{\"a}user Basel",
address="Basel",
pages="123--135",
abstract="The ability of human subjects to discriminate softness was investigated. In addition, the associated mechanistic cues and the peripheral neural codes on which the discrimination may be based were investigated using monkeys. Two sets of compliant objects were constructed: (1) those with a deformable surface, composed of transparent silicone rubber of variable softness; (2) rigid plates supported by springs of variable compliance in cylindrical sleeves. To assess the relative contributions of tactile and kinesthetic information, psychophysical experiments were performed on human subjects under both active and passive touch, with or without local anesthesia that blocked the tactile information from the fingerpads. The results for objects with deformable surfaces show that whereas the subjects are quite good at discriminating subtle differences in softness under both active and passive touch without anesthesia, they are unable to discriminate even large differences under active touch with anesthesia. Therefore, we conclude that the discrimination is based entirely on tactile information. The mechanistic data for rubber specimens indicates that the basis for the perception of softness of rubber-like objects is likely to be the spatio-temporal variation of pressure on the skin (or, equivalently, the skin displacement and its derivatives). Neurophysiological data shows that the resulting responses from slowly adapting type I afferent population within the skin might encode the compliance of the objects. For compliant objects with rigid surfaces best discrimination was achieved only with active touch, due to the availability of both tactile and kinesthetic information; under passive conditions, the absence of kinesthetic information resulted in considerable deterioration of discriminability",
isbn="978-3-0348-9016-8",
memo="10.1007/978-3-0348-9016-8_11",
memo="https://doi.org/10.1007/978-3-0348-9016-8_11"
}

@ARTICLE{4906991,
author={W. M. {Bergmann Tiest} and A. M. L. {Kappers}},
journal={IEEE Transactions on Haptics},
title={Cues for Haptic Perception of Compliance},
year={2009},
volume={2},
number={4},
pages={189-199},
keywords={displacement measurement;elastic constants;force measurement;silicone rubber;Young's modulus;compliance haptic perception;compliant materials hardness;force/displacement relative roles;silicone rubber stimuli;finger span influence;Youngs modulus;Weber fraction;surface deformation cue;optimal cue combination;object thickness difference;Haptic interfaces;Fingers;Rubber;Elasticity;Stress;Capacitive sensors;Thickness measurement;Psychology;Automotive materials;Bicycles;Compliance;hardness;softness;psychophysics;haptic perception;touch.},
memo={10.1109/TOH.2009.16},
ISSN={},
memo={Oct},}

@article{7177694,
author={A. {Metzger} and K. {Drewing}},
journal={In Proceedings of IEEE World Haptics Conference},
title={Haptically perceived softness of deformable stimuli can be manipulated by applying external forces during the exploration},
year={2015},
volume={},
number={},
pages={75-81},
keywords={biomechanics;elastic constants;elastic deformation;integration;silicone rubber;haptically perceived softness;deformable stimuli;multiple cutaneous signals;kinesthetic signals;transmitted subtle external vertical forces;human finger;deformable silicone rubber stimuli;kinesthetic-efference copy information;points-of-subjective equality;integration-of-information;Force;Thumb;Haptic interfaces;Rubber;Atmospheric measurements;Particle measurements},
memo={10.1109/WHC.2015.7177694},
ISSN={},
memo={June},}

@ARTICLE{frisoli2008,
author={A. {Frisoli} and M. {Solazzi} and F. {Salsedo} and M. {Bergamasco}},
journal={Presence},
title={A Fingertip Haptic Display for Improving Curvature Discrimination},
year={2008},
volume={17},
number={6},
pages={550-561},
keywords={},
doi={10.1162/pres.17.6.550},
ISSN={1054-7460},
memo={Dec},}

@article{Chinello2012,
author={F. {Chinello} and M. {Malvezzi} and C. {Pacchierotti} and D. {Prattichizzo}},
journal={In Proceedings of IEEE Haptics Symposium},
title={A three DoFs wearable tactile display for exploration and manipulation of virtual objects},
year={2012},
volume={},
number={},
pages={71-76},
keywords={actuators;cables (mechanical);display instrumentation;force measurement;force sensors;haptic interfaces;numerical analysis;virtual reality;three DoF wearable tactile display;virtual object manipulation;virtual object exploration;wearable haptic display;contact forces;mechanical instrumented system;cables;motors;force sensors;mobile platform;numerical model;fingertip forces;platform orientation;platform displacement;Force;Mobile communication;Haptic interfaces;Force measurement;DC motors;Actuators;Kinematics},
memo={10.1109/HAPTIC.2012.6183772},
ISSN={2324-7347},
memo={March},}

@article{FRISOLI2011260,
title = "The contribution of cutaneous and kinesthetic sensory modalities in haptic perception of orientation",
journal = "Brain Research Bulletin",
volume = "85",
number = "5",
pages = "260 - 266",
year = "2011",
memo = "Presence: Brian, Virtual Reality and Robots",
issn = "0361-9230",
memo = "https://doi.org/10.1016/j.brainresbull.2010.11.011",
memo = "http://www.sciencedirect.com/science/article/pii/S0361923010002698",
author = "Antonio Frisoli and Massimiliano Solazzi and Miriam Reiner and Massimo Bergamasco",
keywords = "Haptic perception, Multisensory integration, Shape recognition",
abstract = "The aim of this study was to understand the integration of cutaneous and kinesthetic sensory modalities in haptic perception of shape orientation. A specific robotic apparatus was employed to simulate the exploration of virtual surfaces by active touch with two fingers, with kinesthetic only, cutaneous only and combined sensory feedback. The cutaneous feedback was capable of displaying the local surface orientation at the contact point, through a small plate indenting the fingerpad at contact. A psychophysics test was conducted with SDT methodology on 6 subjects to assess the discrimination threshold of angle perception between two parallel surfaces, with three sensory modalities and two shape sizes. Results show that the cutaneous sensor modality is not affected by size of shape, but kinesthetic performance is decreasing with smaller size. Cutaneous and kinesthetic sensory cues are integrated according to a Bayesian model, so that the combined sensory stimulation always performs better than single modalities alone."
}

@Article{Voisin2002,
author="Voisin, Julien
and Lamarre, Yves
and Chapman, C. Elaine",
title="Haptic discrimination of object shape in humans: contribution of cutaneous and proprioceptive inputs",
journal="Experimental Brain Research",
year="2002",
memo="Jul",
day="01",
volume="145",
number="2",
pages="251--260",
abstract="Using two-dimensional (2D) angles composed of two straight, 8-cm-long arms that formed an angle, we investigated the importance of cutaneous feedback from the exploring index finger, and proprioceptive feedback from the shoulder (scanning movements made with the outstretched arm), to the human ability to discriminate small differences in the angles. Using a two-alternative forced-choice paradigm, subjects identified the larger angle in each pair explored (standard angle, 90{\textdegree}; comparison angles, 91{\textdegree} to 103{\textdegree}). Subjects were tested under four experimental conditions: (1) active touch (reference condition); (2) active touch with digital anaesthesia; (3) passive touch (a computer-controlled device displaced the angle under the subject's immobile digit); and (4) passive touch with digital anaesthesia. When only proprioceptive feedback from the shoulder was available (condition 2), there was a significant increase in discrimination threshold, from 4.0{\textdegree} in the reference condition (condition 1) to 7.2{\textdegree}, indicating that cutaneous feedback from the exploring digit contributed to task performance. When only cutaneous feedback from the finger was available (condition 3), there was also a significant increase in threshold from 4.2{\textdegree} in the active condition to 8.7{\textdegree}. This suggested that proprioceptive feedback from the shoulder, potentially from a variety of deep (muscle and joint) but also cutaneous receptors, contributed to the ability to discriminate small changes in 2D angles. When both sources of feedback were eliminated (condition 4), subjects were unable to discriminate even the largest difference presented (13{\textdegree}). The results suggest that this sensory task is truly an integrative task drawing on sensory information from two different submodalities and so, following the definition of Gibson, is haptic in nature. The results are discussed in relation to the potential neural mechanisms that might underlie a task that requires integration across two anatomically separate body parts and two distinct modalities.",
issn="1432-1106",
memo="10.1007/s00221-002-1118-5",
memo="https://doi.org/10.1007/s00221-002-1118-5"
}




@ARTICLE{Quek2014,
author={Z. F. {Quek} and S. B. {Schorr} and I. {Nisky} and A. M. {Okamura} and W. R. {Provancher}},
journal={IEEE Transactions on Human-Machine Systems},
title={Augmentation Of Stiffness Perception With a 1-Degree-of-Freedom Skin Stretch Device},
year={2014},
volume={44},
number={6},
pages={731-742},
keywords={augmented reality;force feedback;haptic interfaces;human-robot interaction;actuator force limits;feedback-induced instabilities;force feedback gains;teleoperation scenarios;virtual environment;intersubject variability;slope coefficient;tactor displacement gain;perceived stiffness;additive augmentation;surface stiffness perception;tactor displacement-induced skin stretch;skin stretch device;tool-mediated interactions;fingerpad skin stretch;shear forces;friction;penetration distance;artificial skin stretch stylus;force feedback device;Skin;Haptic interfaces;Force feedback;Friction;Tactile sensors;Haptic devices;physical human–robot interactions;sensory augmentation;skin stretch;stiffness perception;Haptic devices;physical human–robot interactions;sensory augmentation;skin stretch;stiffness perception},
doi={10.1109/THMS.2014.2348865},
ISSN={2168-2291},
memo={Dec},}

@ARTICLE{Quek2015,
author={Z. F. {Quek} and S. B. {Schorr} and I. {Nisky} and W. R. {Provancher} and A. M. {Okamura}},
journal={IEEE Transactions on Haptics},
title={Sensory Substitution and Augmentation Using 3-Degree-of-Freedom Skin Deformation Feedback},
year={2015},
volume={8},
number={2},
pages={209-221},
keywords={force feedback;haptic interfaces;virtual reality;sensory substitution;sensory augmentation;3-degree-of-freedom skin deformation feedback;tool-mediated interaction;kinesthetic force;tactile sensation;vibration;fingerpad skin deformation;tangential skin displacement;normal skin displacement;force information;force-feedback substitution;force-feedback augmentation;3-DoF virtual environment;path-following error reduction;Skin;Force;Force feedback;Performance evaluation;Apertures;Tactile sensors;Haptics;skin deformation;tactile feedback;sensory augmentation;Haptics;skin deformation;tactile feedback;sensory augmentation;Adult;Equipment Design;Feedback, Sensory;Female;Fingers;Humans;Male;Skin Physiological Phenomena;Touch Perception;Young Adult},
memo={10.1109/TOH.2015.2398448},
ISSN={1939-1412},
memo={April},}

@Article{Lederman2009,
author="Lederman, S. J. and Klatzky, R. L.",
title="Haptic perception: A tutorial",
journal="Attention, Perception, and Psychophysics",
year="2009",
memo="Oct",
day="01",
volume="71",
number="7",
pages="1439--1459",
abstract="This tutorial focuses on the sense of touch within the context of a fully active human observer. It is intended for graduate students and researchers outside the discipline who seek an introduction to the rapidly evolving field of human haptics. The tutorial begins with a review of peripheral sensory receptors in skin, muscles, tendons, and joints. We then describe an extensive body of research on ``what'' and ``where'' channels, the former dealing with haptic perception of objects, surfaces, and their properties, and the latter with perception of spatial layout on the skin and in external space relative to the perceiver. We conclude with a brief discussion of other significant issues in the field, including vision-touch interactions, affective touch, neural plasticity, and applications.",
issn="1943-393X",
memo="10.3758/APP.71.7.1439",
memo="https://doi.org/10.3758/APP.71.7.1439"
}


@article{Benko:2016:NTH:2984511.2984526,
 author = {Benko, Hrvoje and Holz, Christian and Sinclair, Mike and Ofek, Eyal},
 title = {NormalTouch and TextureTouch: High-fidelity 3D Haptic Shape Rendering on Handheld Virtual Reality Controllers},
 journal = {In Proceedings of the 29th Annual Symposium on User Interface Software and Technology},
 series = {UIST '16},
 year = {2016},
 isbn = {978-1-4503-4189-9},
 location = {Tokyo, Japan},
 pages = {717--728},
 numpages = {12},
 memo = {http://doi.acm.org/10.1145/2984511.2984526},
 memo = {10.1145/2984511.2984526},
 acmid = {2984526},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {controller design, haptics, tactile display, virtual reality},
} 


@article{Schorr:2017:FTD:3025453.3025744,
 author = {Schorr, Samuel B. and Okamura, Allison M.},
 title = {Fingertip Tactile Devices for Virtual Object Manipulation and Exploration},
 journal = {In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
 series = {CHI '17},
 year = {2017},
 isbn = {978-1-4503-4655-9},
 location = {Denver, Colorado, USA},
 pages = {3115--3119},
 numpages = {5},
 memo = {http://doi.acm.org/10.1145/3025453.3025744},
 memo = {10.1145/3025453.3025744},
 acmid = {3025744},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {haptics, mass perception, virtual reality},
} 


@ARTICLE{6636291,
author={D. {Prattichizzo} and F. {Chinello} and C. {Pacchierotti} and M. {Malvezzi}},
journal={IEEE Transactions on Haptics},
title={Towards Wearability in Fingertip Haptics: A 3-DoF Wearable Device for Cutaneous Force Feedback},
year={2013},
volume={6},
number={4},
pages={506-516},
keywords={computer displays;ergonomics;haptic interfaces;wearable computers;3-DoF wearable device;cutaneous force feedback;fingertip haptics wearability;audio technologies;video technologies;vibrotactile stimulation;force vectors;design guidelines;3-DoF wearable haptic interface;finger pad;parallel robots;wearable display design;curvature discrimination experiment;platform orientation;platform displacement;platform inclination;Haptic interfaces;Wearable computers;Mobile communication;Fingers;Load modeling;Haptic interfaces;force feedback;wearable computers;portable computers;Adult;Algorithms;Biomechanical Phenomena;Computers;Feedback;Female;Fingers;Humans;Male;Robotics;Task Performance and Analysis;Touch;User-Computer Interface},
memo={10.1109/TOH.2013.53},
ISSN={},
month={Oct},}

@article{Minamizawa:2007:GGW:1278280.1278289,
 author = {Minamizawa, Kouta and Fukamachi, Souichiro and Kajimoto, Hiroyuki and Kawakami, Naoki and Tachi, Susumu},
 title = {Gravity Grabber: Wearable Haptic Display to Present Virtual Mass Sensation},
 journal = {ACM SIGGRAPH 2007 Emerging Technologies},
 series = {SIGGRAPH '07},
 year = {2007},
 isbn = {978-1-4503-1824-2},
 location = {San Diego, California},
 articleno = {8},
 memo = {http://doi.acm.org/10.1145/1278280.1278289},
 memo = {10.1145/1278280.1278289},
 acmid = {1278289},
 publisher = {ACM},
 address = {New York, NY, USA},
} 


@article{Leithinger:2010:RSA:1709886.1709928,
 author = {Leithinger, Daniel and Ishii, Hiroshi},
 title = {Relief: A Scalable Actuated Shape Display},
 booktitle = {Proceedings of the Fourth International Conference on Tangible, Embedded, and Embodied Interaction},
 series = {TEI '10},
 year = {2010},
 isbn = {978-1-60558-841-4},
 location = {Cambridge, Massachusetts, USA},
 pages = {221--222},
 numpages = {2},
 memo = {http://doi.acm.org/10.1145/1709886.1709928},
 memo = {10.1145/1709886.1709928},
 acmid = {1709928},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {haptic display, pin array, relief interface, shape display, tangible input},
} 

@article{Jang:2016:HED:2858036.2858264,
 author = {Jang, Sungjune and Kim, Lawrence H. and Tanner, Kesler and Ishii, Hiroshi and Follmer, Sean},
 title = {Haptic Edge Display for Mobile Tactile Interaction},
 journal = {In Proceedings of CHI Conference on Human Factors in Computing Systems},
 series = {CHI '16},
 year = {2016},
 isbn = {978-1-4503-3362-7},
 location = {San Jose, California, USA},
 pages = {3706--3716},
 numpages = {11},
 memo = {http://doi.acm.org/10.1145/2858036.2858264},
 memo = {10.1145/2858036.2858264},
 acmid = {2858264},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {dynamic affordance, mobile haptics, tactile display},
} 

@article{Velazquez2005,
author={R. {Velazquez} and E. {Pissaloux} and M. {Hafez} and J. {Szewczyk}},
journal={In Proceedings of IEEE Symposium on Virtual Environments, Human-Computer Interfaces and Measurement Systems},
title={A low-cost highly-portable tactile display based on shape memory alloy micro-actuators},
year={2005},
volume={},
number={},
pages={6 pp.-},
keywords={haptic interfaces;shape memory effects;microactuators;portable tactile display;shape memory alloy microactuators;tactile actuator;forced-air convection;1.5 Hz;0.060 kg;Shape memory alloys;Microactuators;Prototypes;Actuators;Costs;Bandwidth;Computer displays;Piezoelectric devices;Two dimensional displays;Graphics},
memo={10.1109/VECIMS.2005.1567577},
ISSN={},
month={July},}

@article{Moy2000,
author={G. {Moy} and C. {Wagner} and R. S. {Fearing}},
journal={In Proceedings of IEEE International Conference on Robotics and Automation. Symposia Proceedings},
title={A compliant tactile display for teletaction},
year={2000},
volume={4},
number={},
pages={3409-3415 vol.4},
keywords={haptic interfaces;force feedback;silicone rubber;pneumatic control equipment;tactile display;teletaction;fabrication;pneumatic-actuators;silicone rubber;display compliance;contact interface;Displays;Shape;Machining;Assembly;Fabrication;Rubber;Fingers;Seals;Friction;Psychology},
memo={10.1109/ROBOT.2000.845247},
ISSN={},
month={April},}

@article{hayward2000tactile,
  title={Tactile display device using distributed lateral skin stretch},
  author={Hayward, Vincent and Cruz-Hernandez, M},
  journal={In Proceedings of the haptic interfaces for virtual environment and teleoperator systems symposium},
  volume={69},
  number={2},
  pages={1309--1314},
  year={2000},
  organization={Citeseer}
}

@article{Kajimoto2014,
 author = {Kajimoto, Hiroyuki and Suzuki, Masaki and Kanno, Yonezo},
 title = {HamsaTouch: Tactile Vision Substitution with Smartphone and Electro-tactile Display},
 journal = {In Proceedings of ACM Conference on Human Factors in Computing Systems},
 series = {CHI EA '14},
 year = {2014},
 isbn = {978-1-4503-2474-8},
 location = {Toronto, Ontario, Canada},
 pages = {1273--1278},
 numpages = {6},
 memo = {http://doi.acm.org/10.1145/2559206.2581164},
 memo = {10.1145/2559206.2581164},
 acmid = {2581164},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {electro-tactile display, optical communication, reading aid, smartphone, tactile vision substitution system, visually impaired},
} 
[download]
@inproceedings{Kajimoto:2014:HTV:2559206.2581164,
 author = {Kajimoto, Hiroyuki and Suzuki, Masaki and Kanno, Yonezo},
 title = {HamsaTouch: Tactile Vision Substitution with Smartphone and Electro-tactile Display},
 booktitle = {CHI '14 Extended Abstracts on Human Factors in Computing Systems},
 series = {CHI EA '14},
 year = {2014},
 isbn = {978-1-4503-2474-8},
 location = {Toronto, Ontario, Canada},
 pages = {1273--1278},
 numpages = {6},
 url = {http://doi.acm.org/10.1145/2559206.2581164},
 doi = {10.1145/2559206.2581164},
 acmid = {2581164},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {electro-tactile display, optical communication, reading aid, smartphone, tactile vision substitution system, visually impaired},
} 


@INPROCEEDINGS{Wang2006, 
author={ {Qi Wang} and V. {Hayward}}, 
booktitle={2006 14th Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems}, 
title={Compact, Portable, Modular, High-performance, Distributed Tactile Transducer Device Based on Lateral Skin Deformation}, 
year={2006}, 
volume={}, 
number={}, 
pages={67-72}, 
keywords={tactile displays;haptic devices;virtual reality;Transducers;Skin;Actuators;Spatial resolution;Millimeter wave devices;Bandwidth;Application software;Fabrication;Assembly;Debugging;tactile displays;haptic devices;virtual reality}, 
doi={10.1109/HAPTIC.2006.1627091}, 
ISSN={}, 
month={March},}

@article{Kim2006,
author="Kim, Yeongmi
and Kim, Sehun
and Ha, Taejin
and Oakley, Ian
and Woo, Woontack
and Ryu, Jeha",
editor="Pan, Zhigeng
and Cheok, Adrian
and Haller, Michael
and Lau, Rynson W. H.
and Saito, Hideo
and Liang, Ronghua",
title="Air-Jet Button Effects in AR",
journal="In Proceedings of Advances in Artificial Reality and Tele-Existence",
year="2006",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="384--391",
abstract="Providing haptic cues can generate increased levels of presence in users as they interact with tangible objects. In this paper, we present button effects delivered by air-jet displays with the aim of providing click-like sensations when virtual buttons in an AR environment are pressed. We derive the profile of the haptic output by measuring the force profile of real physical buttons. To validate our concept, we have built an AR system featuring a cellular phone model which users can tangibly manipulate through a physical AR marker object. When users press a button on the model, they experience a corresponding click-like feeling at their fingertip. In this way, our system enables users to press a button on an AR model and experience a force profile generated by our pneumatic array directly derived from the act of pushing a button in the real world.",
isbn="978-3-540-49779-0"
}

@article{Sarakoglou2005,
author={I. {Sarakoglou} and N. {Tsagarakis} and D. G. {Caldwell}},
journal={In Proceedings of First Joint Eurohaptics Conference and Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems. World Haptics Conference},
title={A portable fingertip tactile feedback array - transmission system reliability and modelling},
year={2005},
volume={},
number={},
pages={547-548},
keywords={haptic interfaces;force feedback;portable fingertip tactile feedback array;transmission system reliability;portable- wearable tactile display;miniature remotely located motor;texture simulation;Feedback;Reliability;Displays;DC motors;Tendons;Pins;Batteries;Bandwidth;Fingers;Skin},
doi={10.1109/WHC.2005.17},
ISSN={},
memo={March},}

@article{Caldwell1999,
author={D. G. {Caldwell} and N. {Tsagarakis} and C. {Giesler}},
journal={In Proceedings of IEEE International Conference on Robotics and Automation},
title={An integrated tactile/shear feedback array for stimulation of finger mechanoreceptor},
year={1999},
volume={1},
number={},
pages={287-292 vol.1},
keywords={tactile sensors;haptic interfaces;pressure control;virtual reality;telecontrol;force feedback;integrated tactile/shear feedback array;finger mechanoreceptor;tactile feedback;cutaneous aspects;pneumatically powered modules;mechano-receptive nerves;Fingers;Haptic interfaces;Virtual reality;Vibrations;Temperature sensors;Sensor arrays;Displays;Thermal conductivity;Force feedback;Humans},
doi={10.1109/ROBOT.1999.769991},
ISSN={1050-4729},
memo={May},}


@article{tanabe2015whole,
  title={The whole hand haptic glove using numerous linear resonant actuators},
  author={Tanabe, Kenta and Takei, Seiya and Kajimoto, Hiroyuki},
  journal={In Proceedings of IEEE World Haptics Conference},
  year={2015}
}

@article{taniguchi,
author="Taniguchi, Takaaki
and Sakurai, Sho
and Nojima, Takuya
and Hirota, Koichi",
editor="Prattichizzo, Domenico
and Shinoda, Hiroyuki
and Tan, Hong Z.
and Ruffaldi, Emanuele
and Frisoli, Antonio",
title="Multi-point Pressure Sensation Display Using Pneumatic Actuators",
journal="In Proceedings of EuroHaptics Conference 2018",
year="2018",
publisher="Springer International Publishing",
address="Cham",
pages="58--67",
}


@article{Kim2009,
author={S. {Kim} and C. {Kim} and G. {Yang} and T. {Yang} and B. {Han} and S. {Kang} and D. {Kwon}},
journal={In Proceedings of IEEE World Haptics Conference 2009},
title={Small and lightweight tactile display(SaLT) and its application},
year={2009},
volume={},
number={},
pages={69-74},
keywords={haptic interfaces;piezoelectric actuators;lightweight tactile display;tactile feedback;piezoelectric ultrasonic actuator array;display modules;Displays;Haptic interfaces;Hydraulic actuators;Feedback;Piezoelectric actuators;Polymer films;Friction;Frequency;Bandwidth;Skin;tactile display;texture},
doi={10.1109/WHC.2009.4810820},
ISSN={},
memo={March},}

@ARTICLE{Koo2008,
author={I. M. {Koo} and K. {Jung} and J. C. {Koo} and J. {Nam} and Y. K. {Lee} and H. R. {Choi}},
journal={IEEE Transactions on Robotics},
title={Development of Soft-Actuator-Based Wearable Tactile Display},
year={2008},
volume={24},
number={3},
pages={549-558},
keywords={actuators;display devices;haptic interfaces;tactile sensors;wearable tactile display device;innovative tactile display device;soft actuator technology;electroactive polymer;miniaturization;flexible structure;human-machine interface;human sensory function;tactile sensation;Displays;Humans;Man machine systems;Actuators;Polymers;Skin;Fabrication;Costs;Mass production;Flexible structures;Electroactive polymer (EAP);tactile display;wearable;Electroactive polymer (EAP);tactile display;wearable},
doi={10.1109/TRO.2008.921561},
ISSN={1552-3098},
memo={June},}


@ARTICLE{Howe,
author={R. D. {Howe} and W. J. {Peine} and D. A. {Kantarinis} and J. S. {Son}},
journal={IEEE Engineering in Medicine and Biology Magazine},
title={Remote palpation technology},
year={1995},
volume={14},
number={3},
pages={318-323},
keywords={surgery;tactile sensors;biomedical equipment;manipulators;remote palpation technology;anatomical structures;pathologies;minimally invasive procedures;laparoscopy;thoracoscopy;robotic manipulators;surgeon's perception;video camera visual feedback;sensory deficit;tactile information relay;probe;surgical instrument;tactile information;tactile display devices;surgeon's finger tip;conventional open-incision surgery;force reflection;vibration;small-scale shape;Surges;Force feedback;Fingers;Tactile sensors;Anatomical structure;Pathology;Minimally invasive surgery;Laparoscopes;Robot sensing systems;Manipulators},
doi={10.1109/51.391770},
ISSN={0739-5175},
memo={May},}

@Article{Shimizu1993,
author="Shimizu, Yutaka
and Saida, Shinya
and Shimura, Hiroshi",
title="Tactile pattern recognition by graphic display: Importance of 3-D information for haptic perception of familiar objects",
journal="Perception {\&} Psychophysics",
year="1993",
memo="Jan",
day="01",
volume="53",
number="1",
pages="43--48",
abstract="Haptic recognition of familiar objects by the early blind, the late blind, and the sighted was investigated with two-dimensional (2-D) and three-dimensional (3-D) stimuli produced by small tactor-pins. The 2-D stimulus was an outline of an object that was depicted by raising tactor-pins to 1.5 mm. The 3-D stimulus was a relief that was produced by raising the tactors up to 10 mm, corresponding to the height of the object. Mean recognition times for correct answers to the 3-D stimuli were faster than those for the 2-D stimuli, in all three subject groups. No statistically significant differences in percentage of correct responses between the 2-D and the 3-D stimuli were found for the late-blind and sighted groups, but the early-blind group demonstrated a significant difference. In addition, the haptic legibility for the quality of depiction of the object, without regard to whether or not the stimulus was understood, was measured. The haptic legibility of the 3-D stimuli was significantly higher than that of the 2-D stimuli for all the groups. These results suggest that 3-D presentation seems to promise a way to overcome the limitations of 2-D graphic display.",
issn="1532-5962",
memo="10.3758/BF03211714",
memo="https://doi.org/10.3758/BF03211714"
}



@Article{Norman2004,
author="Norman, J. Farley
and Norman, Hideko F.
and Clayton, Anna Marie
and Lianekhammy, Joann
and Zielke, Gina",
title="The visual and haptic perception of natural object shape",
journal="Perception {\&} Psychophysics",
year="2004",
memo="Feb",
day="01",
volume="66",
number="2",
pages="342--351",
abstract="In this study, we evaluated observers' ability to compare naturally shaped three-dimensional (3-D) objects, using their senses of vision and touch. In one experiment, the observers haptically manipulated 1 object and then indicated which of 12 visible objects possessed the same shape. In the second experiment, pairs of objects were presented, and the observers indicated whether their 3-D shape was thesame ordifferent. The 2 objects were presented either unimodally (vision-vision or haptic-haptic) or cross-modally (vision-haptic or haptic-vision). In both experiments, the observers were able to compare 3-D shape across modalities with reasonably high levels of accuracy. In Experiment 1, for example, the observers' matching performance rose to 72 correct (chance performance was 8.3 after five experimental sessions. In Experiment 2, small (but significant) differences in performance were obtained between the unimodal vision-vision condition and the two cross-modal conditions. Taken together, the results suggest that vision and touch have functionally overlapping, but not necessarily equivalent, representations of 3-D shape.",
issn="1532-5962",
memo="10.3758/BF03194883",
memo="https://doi.org/10.3758/BF03194883"
}

@Article{Klatzky1985,
author="Klatzky, Roberta L.
and Lederman, Susan J.
and Metzger, Victoria A.",
title="Identifying objects by touch: An ``expert system''",
journal="Perception {\&} Psychophysics",
year="1985",
memo="Jul",
day="01",
volume="37",
number="4",
pages="299--302",
abstract="How good are we at recognizing objects by touch? Intuition may suggest that the haptic system is a poor recognition device, and previous research with nonsense shapes and tangible-graphics displays supports this opinion. We argue that the recognition capabilities of touch are best assessed with three-dimensional, familiar objects. The present study provides a baseline measure of recognition under those circumstances, and it indicates that haptic object recognition can be both rapid and accurate.",
issn="1532-5962",
memo="10.3758/BF03211351",
memo="https://doi.org/10.3758/BF03211351"
}

@article{Fukumoto2001,
abstract = {{\{}"Active{\}} Click" is a new interface mechanism for addling tactile$\backslash$nfeedback to touch panels. A small actuator is attached to a body$\backslash$nof {\{}PDA{\}} or the backside of a touch panel. The tactile feedback,$\backslash$ncreated by driving the actuator with a short pulse, is perceived$\backslash$nby the grasping hand or tapping finger-tip when the panel is tapped.$\backslash$nActive Click is effective in improving the input speed of touch panel$\backslash$noperation especially in noisy situations. Active click is also useful$\backslash$nfor large touch panel devices such as public information terminals$\backslash$nor {\{}ATMs.{\}}},
author = {Fukumoto, Masaaki and Sugimura, Toshiaki},
doi = {10.1145/634067.634141},
isbn = {1-58113-340-5},
journal = {{\{}CHI{\}} '01 extended abstracts on Human factors in computing systems},
keywords = {click,interface device,pda,touch panel},
number = {Figure 1},
pages = {121--122},
title = {{Active click: tactile feedback for touch panels}},
url = {http://portal.acm.org/citation.cfm?id=634141},
year = {2001}
}

@inproceedings{Ito:2019:WLM:3343036.3343139,
 author = {Ito, Ryota and Ogawa, Nami and Narumi, Takuji and Hirose, Michitaka},
 title = {Do We Have to Look at the Mirror All the Time? Effect of Partial Visuomotor Feedback on Body Ownership of a Virtual Human Tail},
 booktitle = {ACM Symposium on Applied Perception 2019},
 series = {SAP '19},
 year = {2019},
 isbn = {978-1-4503-6890-2},
 location = {Barcelona, Spain},
 pages = {8:1--8:9},
 articleno = {8},
 numpages = {9},
 memo = {http://doi.acm.org/10.1145/3343036.3343139},
 memo = {10.1145/3343036.3343139},
 acmid = {3343139},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Extended Humanoid Avatar, Sense of Body Ownership, Virtual Environment, Visuomotor Synchrony},
} 

@article{Minsky:1984:MSO:964965.808598,
 author = {Minsky, Margaret R.},
 title = {Manipulating Simulated Objects with Real-world Gestures Using a Force and Position Sensitive Screen},
 journal = {SIGGRAPH Comput. Graph.},
 issue_date = {July 1984},
 volume = {18},
 number = {3},
 month = jan,
 year = {1984},
 issn = {0097-8930},
 pages = {195--203},
 numpages = {9},
 url = {http://doi.acm.org/10.1145/964965.808598},
 doi = {10.1145/964965.808598},
 acmid = {808598},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Computers and education, Gesture, Paint programs, Touch-sensitive screen, Visual programming},
}

@article{Kajimoto2012,
abstract = {An electro-tactile display is a possible candidate for a truly tangible multi-touch interface for four reasons. First, it only requires an electrode substrate that can be made transparent and thin. Second, it has a potential to present high-resolution tactile information of 3mm or less, which is preferable for shape presentation. Third, it's principle is active so that it does not require user's finger motion. Fourth, the electrical stimulation can be innately used for multi-touch sensing. This paper introduces a prototype transparent electro-tactile display mounted on mobile devices. Copyright {\textcopyright} 2012 ACM, Inc.},
author = {Kajimoto, Hiroyuki},
doi = {10.1145/2407707.2407728},
isbn = {9781450319126},
journal = {SIGGRAPH Asia 2012 Emerging Technologies on - SA '12},
keywords = {electrical stimulation,haptics,tactile display,trans-},
pages = {1--3},
title = {{Skeletouch: transparent electro-tactile display for mobile surfaces}},
url = {http://dl.acm.org/citation.cfm?doid=2407707.2407728},
year = {2012}
}

@article{Lecuyer2009,
abstract = {... The pseudo - haptic texture technique is then applied to the visual motions of the cursor, to simulate the bumps and ...  haptic  feedback differs from “active” haptic  feedback in that it does not necessarily re- quire a haptic interface. ... Secondly, pseudo - haptic  feedback differs from ... $\backslash$n},
author = {L{\'{e}}cuyer, A},
journal = {Presence},
file = {:Users/Ujitoko/Library/Application Support/Mendeley Desktop/Downloaded/L{\'{e}}cuyer, L{\'{e}}cuyer - 2009 - Simulating Haptic Feedback Using Vision A Survey of Research and Applications of Pseudo-Haptic Feedback.pdf:pdf},
pages = {39--53},
title = {{Simulating haptic feedback using vision: A survey of research and applications of pseudo-haptic feedback}},
volume = {18},
year = {2009}
}

@InProceedings{Lecuyer2000,
abstract = {This paper considers whether a passive isometric input device,
such as a Spaceball{\textless}sup{\textgreater}TM{\textless}/sup{\textgreater}, used together with visual feedback,
could provide the operator with a pseudo-haptic feedback. For this aim,
two psychophysical experiments have been conducted. The first experiment
consisted of a compliance discrimination, between two virtual springs
hand-operated by means of the Spaceball{\textless}sup{\textgreater}TM{\textless}/sup{\textgreater}. In this
experiment, the stiffness (or compliance) JND turned out to be 6{\%}. The
second experiment assessed stiffness discrimination between a virtual
spring and the equivalent spring in reality. In this case, the stiffness
(or compliance) JND was found to be 13.4{\%}. These results are consistent
with previous outcomes on manual discrimination of compliance.
Consequently, this consistency reveals that the passive apparatus that
was used can, to some extent, simulate haptic information. In addition,
a final test indicated that the proprioceptive sense of the subjects was
blurred by visual feedback. This gave them the illusion of using a
nonisometric device},
author = {Lecuyer, A. and Coquillart, S. and Kheddar, A. and Richard, P. and Coiffet, P.},
memo = {10.1109/VR.2000.840369},
file = {:Users/Ujitoko/Library/Application Support/Mendeley Desktop/Downloaded/Lecuyer et al. - 2000 - Pseudo-haptic feedback can isometric input devices simulate force feedback.pdf:pdf},
isbn = {0-7695-0478-7},
issn = {1087-8270},
booktitle = {Proceedings IEEE Virtual Reality},
title = {{Pseudo-haptic feedback: can isometric input devices simulate force
feedback?}},
year = {2000}
}

@inproceedings{Narumi2017,
abstract = {This paper proposes a novel method named {\&}{\#}x201C;Resistive swipe{\&}{\#}x201D; that renders haptic perceptions only using a touch screen based on visuo-haptic interaction. The method evokes a feeling of resistive force by creating a discrepancy between the movement of the finger during swiping the screen and the background image shown on the screen. Through two experiments, this study shows that the {\&}{\#}x201C;Resistive Swipe{\&}{\#}x201D; can evoke perception of resistance according to the constant ratio between the displacement of the finger and background image (the user perceives strong resistance to move when the background image moves slower than the finger). Moreover, the experiments also suggested that the evoked haptic perception becomes stronger when the method is applied to frequently repeated movements. These features suggested that the mechanism to evoke haptic perception in the proposed approach differs from that in the conventional pseudo-haptic approach. Because the {\&}{\#}x201C;Resistive Swipe{\&}{\#}x201D; is simple and easy to implement on ordinary smartphone/tablet applications that use swipe gestures to scroll the background image, it opens up a new possibility of haptic feedback on touch panels.},
author = {Narumi, Takuji and Ujitoko, Yusuke and Ban, Yuki and Tanikawa, Tomohiro and Hirota, Koichi and Hirose, Michitaka},
booktitle = {2017 IEEE World Haptics Conference, WHC 2017},
doi = {10.1109/WHC.2017.7989924},
isbn = {9781509014255},
pages = {334--339},
title = {{Resistive swipe: Visuo-haptic interaction during swipe gestures to scroll background images on touch interfaces}},
year = {2017}
}

@article{Robles-De-La-Torre2006,
abstract = {What would be worse, losing your sight or your sense of touch? Although touch (more generally, somesthesis) is commonly underrated, major somesthetic loss can't be adequately compensated for by sight. It results in catastrophic impairments of hand dexterity, haptic capabilities, walking, perception of limb position, and so on. Providing users with inadequate somesthetic feedback in virtual environments might impair their performance, just as major somesthetic loss does},
author = {Robles-De-La-Torre, Gabriel},
doi = {10.1109/MMUL.2006.69},
isbn = {1070-986X},
issn = {1070986X},
journal = {IEEE Multimedia},
number = {3},
pages = {24--30},
title = {{The Importance of the sense of touch in virtual and real environments}},
volume = {13},
year = {2006}
}

@InProceedings{Watanabe2008,
abstract = {This paper presents a survey of the main results obtained in the field of “pseudo-haptic feedback”: a technique meant to simulate haptic sensations in virtual environments using visual feedback and properties of human visuo-haptic perception. Pseudo-haptic feedback uses vision to distort haptic perception and verges on haptic illusions. Pseudo-haptic feedback has been used to simulate various haptic properties such as the stiffness of a virtual spring, the texture of an image, or the mass of a virtual object. This paper describes the several experiments in which these haptic properties were simulated. It assesses the definition and the properties of pseudo-haptic feedback. It also describes several virtual reality applications in which pseudo-haptic feedback has been successfully implemented, such as a virtual environment for vocational training of milling machine operations, or a medical simulator for training in regional anesthesia procedures. 2},
author = {Watanabe, Keita and Yasumura, Michiaki},
memo = {10.1145/1501750.1501856},
isbn = {978-1-60558-393-8},
booktitle = {Proceedings of the International Conference on Advances in Computer Entertainment Technology},
keywords = {GUI,feeling,haptics,human senses},
pages = {405},
title = {{VisualHaptics: Generating Haptic Sensation Using Only Visual Cues}},
url = {http://doi.acm.org/10.1145/1501750.1501856},
volume = {246},
year = {2008}
}

@inproceedings{Ujitoko2015,
abstract = {"Yubi-Toko" is a touchpad system in which users can walk in a snowy scene using their fingers and feel the difficulty in moving forward caused as generated by a pseudo-haptic technique (Fig. 1).},
author = {Ujitoko, Y. and Tanikawa, T. and Ban, Y. and Hirota, K. and Narumi, T. and Hirose, M.},
booktitle = {SIGGRAPH Asia 2015 Emerging Technologies, SA 2015},
doi = {10.1145/2818466.2818491},
isbn = {9781450339254},
title = {{Yubi-toko: Finger walking in snowy scene using pseudo-haptic technique on touchpad}},
year = {2015}
}

@incollection{Kim2008,
author = {Kim, Ji-Sun and Gra{\v{c}}anin, Denis and Matkovi{\'{c}}, Kre{\v{s}}imir and Quek, Francis},
booktitle = {Smart Graphics SE  - 6},
doi = {10.1007/978-3-540-85412-8_6},
editor = {Butz, Andreas and Fisher, Brian and Kr{\"{u}}ger, Antonio and Olivier, Patrick and Christie, Marc},
isbn = {978-3-540-85410-4},
keywords = {Finger-walking,Multi-touch device,Navigation,Traveling techniques,Virtual environments},
language = {English},
pages = {58--69},
publisher = {Springer Berlin Heidelberg},
series = {Lecture Notes in Computer Science},
title = {{Finger Walking in Place (FWIP): A Traveling Technique in Virtual Environments}},
url = {http://dx.doi.org/10.1007/978-3-540-85412-8{\_}6},
volume = {5166},
year = {2008}
}

@article{Iwata1999,
abstract = {Locomotion in virtual environments (VEs) remains one of the major
problems in current virtual reality research. The most intuitive way to
move about the real world is to travel on foot. People often feel a
better sense of distance or direction while walking than while riding in
a vehicle. This article discusses the development of a locomotion device
that provides a sense of walking. In terms of natural interaction, the
physical exertion of walking proves essential to locomotion. The
research of my colleagues and I aims to give users a sense of walking
while their position remains localized in the physical world. We've
developed several prototypes of interface devices for walking. From the
results of our research, we concluded that an infinite surface would
offer an ideal means for giving people a sense of walking. Our device,
called the Torus Treadmill, uses a torus-shaped surface to realize the
locomotion interface. The surface employs 12 sets of treadmills
connected side-by-side and driven in a perpendicular direction. These
treadmills generate an infinite surface. We measured the motion of the
users' feet with magnetic sensors. The floor moves in the opposite
direction of the walker, canceling the motion of each step. The walker's
position remains localized in the real world by this computer-controlled
motion of the floor. The walker can freely change direction. An image of
the virtual space appears in a head-mounted display corresponding to the
walker's virtual position},
author = {Iwata, Hiroo},
doi = {10.1109/38.799737},
issn = {02721716},
journal = {IEEE Computer Graphics and Applications},
pages = {30--35},
title = {{Torus Treadmill: Realizing locomotion in VEs}},
volume = {19},
year = {1999}
}

@article{Darken1997,
abstract = {The Omni-Directional Treadmill (ODT) is a revolutionary device for locomotion in large-scale virtual environments. The device allows its user to walk or jog in any direction of travel. It is the third generation in a series of devices built for this purpose for the U.S. Army's Dismounted Infantry Training Program. We first describe the device in terms of its construction and operating characteristics. We then report on an analysis consisting of a series of locomotion and maneuvering tasks on the ODT. We observed user motions and system responses to those motions from the perspective of the user. Each task is described in terms of what causes certain motions to trigger unpredictable responses causing loss of balance or at least causing the user to become consciously aware of their movements. We conclude that the two primary shortcomings in the ODT are its tracking system and machine control mechanism for centering the user on the treads.},
author = {Darken, RP and Cockayne, WR and Carmein, David},
doi = {10.1145/263407.263550},
isbn = {0897918819},
journal = {{\ldots} of the 10th annual ACM {\ldots}},
keywords = {WEM HCII2011,WEM VR2012,WEM dissertation},
pages = {213--221},
title = {{The omni-directional treadmill: a locomotion device for virtual worlds}},
url = {http://dl.acm.org/citation.cfm?id=263550},
year = {1997}
}

@article{Blanch2004,
abstract = {We introduce semantic pointing, a novel interaction technique that improves target acquisition in graphical user interfaces (GUIs). Semantic pointing uses two independent sizes for each potential target presented to the user: one size in motor space adapted to its importance for the manipulation, and one size in visual space adapted to the amount of information it conveys. This decoupling between visual and motor size is achieved by changing the control-to-display ratio according to cursor distance to nearby targets. We present a controlled experiment supporting our hypothesis that the performance of semantic pointing is given by Fitts' index of difficulty in motor rather than visual space. We apply semantic pointing to the redesign of traditional GUI widgets by taking advantage of the independent manipulation of motor and visual widget sizes.},
author = {Blanch, Renaud and Guiard, Yves and Beaudouin-Lafon, Michel},
doi = {10.1145/985692.985758},
file = {:Users/Ujitoko/Library/Application Support/Mendeley Desktop/Downloaded/Blanch, Guiard, Beaudouin-Lafon - 2004 - Semantic pointing.pdf:pdf},
isbn = {1581137028},
journal = {Chi '04},
keywords = {Fitts' law,control-display ratio,graphical user interface,pointing,semantic pointing},
number = {1},
pages = {519--526},
title = {{Semantic pointing}},
volume = {6},
year = {2004}
}

@article{Ahlstr2006,
abstract = {In this paper we explore the usage of "force fields" in order to facilitate the computer user during pointing tasks. The first study shows that pointing time can be reduced by enhancing a pointing target with an invisible force field that warps the screen cursor toward the target center. The application of force fields is further supported in that we show how performance of force enhanced pointing can be predicted by using Fitts' law and a force adjusted index of difficulty. In the second study, the force field technique is compared with the "sticky target" technique [20] in two realistic pointing situations which involve several closely placed targets. The results show that the force fields improve pointing performance and that the sticky target technique does not.},
author = {Ahlstr, David and Hitz, Martin and Leitner, Gerhard},
doi = {10.1145/1182475.1182482},
file = {:Users/Ujitoko/Library/Application Support/Mendeley Desktop/Downloaded/Ahlstr, Hitz, Leitner - 2006 - An Evaluation of Sticky and Force Enhanced Targets in Multi Target Situations.pdf:pdf},
isbn = {1595933255},
journal = {NordiCHI '06: Proceedings of the 4th Nordic conference on Human-computer interaction: changing roles},
pages = {58--67},
title = {{An Evaluation of Sticky and Force Enhanced Targets in Multi Target Situations}},
year = {2006}
}

@article{Dominjon2005,
abstract = {This paper describes two psychophysical experiments which were conducted to evaluate the influence of the control/display (C/D) ratio on the perception of mass of manipulated objects in virtual environments (VE). In both experiments, a discrimination task was used in which participants were asked to identify the heavier object between two virtual balls. Participants could weigh each ball via a haptic interface and look at its synthetic display on a computer screen. Unknown to the participants, two parameters varied between each trial: the difference of mass between the balls and the C/D ratio used in the visual display when weighing the comparison ball. The data collected demonstrated that the C/D ratio significantly influenced the result of the mass discrimination task and sometimes even reversed it. The absence of gravity force largely increased this effect. These results suggest that if the visual motion of a manipulated virtual object is amplified when compared to the actual motion of the user's hand (i.e. if the C/D ratio used is smaller than 1), the user tends to feel that the mass of the object decreases. Thus, decreasing or amplifying the motions of the user in a VE can strongly modify the perception of haptic properties of objects that he/she manipulates. Designers of virtual environments could use these results for simplification considerations and also to avoid potential perceptual aberrations.},
author = {Dominjon, L. and Lecuyer, A. and Burkhardt, J.-M. and Richard, P. and Richir, S.},
doi = {10.1109/VR.2005.1492749},
file = {:Users/Ujitoko/Library/Application Support/Mendeley Desktop/Downloaded/Dominjon et al. - 2005 - Influence of controldisplay ratio on the perception of mass of manipulated objects in virtual environments.pdf:pdf},
isbn = {0-7803-8929-8},
issn = {1},
journal = {IEEE Proceedings. VR 2005. Virtual Reality, 2005.},
title = {{Influence of control/display ratio on the perception of mass of manipulated objects in virtual environments}},
year = {2005}
}

@inproceedings{TaimaControl,
author = {Taima, Y and Ban, Y and Narumi, T and Tanikawa, T and Hirose, M},
booktitle = {Haptics Symposium (HAPTICS), 2014 IEEE},
doi = {10.1109/HAPTICS.2014.6775451},
file = {:Users/Ujitoko/Library/Application Support/Mendeley Desktop/Downloaded/Taima et al. - 2014 - Controlling fatigue while lifting objects using Pseudo-haptics in a mixed reality space.pdf:pdf},
keywords = {fatigue;haptic interfaces;virtual reality;MR weigh},
pages = {175--180},
title = {{Controlling fatigue while lifting objects using Pseudo-haptics in a mixed reality space}},
year = {2014}
}

@inproceedings{Ban2012,
abstract = {Abstract In our research, we aim to construct a visuo- haptic system that can provide users with the sensation of touching virtual objects of varying shapes , using pseudo - haptic effects . In this paper, we focus on modifying the identification of a shape of a curved surface when ... $\backslash$n},
author = {Ban, Yuki and Kajinami, Takashi and Narumi, Takuji and Tanikawa, Tomohiro and Hirose, Michitaka},
memo = {10.1109/HAPTIC.2012.6183793},
file = {:Users/Ujitoko/Library/Application Support/Mendeley Desktop/Downloaded/Ban et al. - 2012 - Modifying an identified curved surface shape using pseudo-haptic effect.pdf:pdf},
isbn = {9781467308090},
journal = {IEEE Haptics Symposium},
memo = {Haptics Symposium 2012, HAPTICS 2012 - Proceedings},
keywords = {Identified Shape Modification,Pseudo-haptics,Visuo-haptic interaction},
pages = {211--216},
title = {{Modifying an identified curved surface shape using pseudo-haptic effect}},
year = {2012}
}

@InProceedings{Lecuyer2004,
abstract = {We present a new interaction technique to simulate textures in desktop applications without a haptic interface. The proposed technique consists in modifying the motion of the cursor on the computer screen \UTF{2013} i.e. the Control/Display ratio. Assuming that the image displayed on the screen corresponds to a top view of the texture, an acceleration (or deceleration) of the cursor indicates a negative (or positive) slope of the texture. Experimental evaluations showed that participants could successfully identify macroscopic textures such as bumps and holes, by simply using the variations of the motion of the cursor. Furthermore, the participants were able to draw the different profiles of bumps and holes which were simulated, correctly. These results suggest that our technique enabled the participants to successfully conjure a mental image of the topography of the macroscopic textures. Applications for this technique are: the feeling of images (pictures, drawings) or GUI components (windows' edges, buttons), the improvement of navigation, or the visualization of scientific data.},
author = {L{\'{e}}cuyer, Anatole and Burkhardt, Jean-Marie and Etienne, Laurent},
memo = {10.1145/985692.985723},
file = {:Users/Ujitoko/Library/Application Support/Mendeley Desktop/Downloaded/L{\'{e}}cuyer, Burkhardt, Etienne - 2004 - Feeling bumps and holes without a haptic interface the perception of pseudo-haptic textures.pdf:pdf},
isbn = {1581137028},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
keywords = {bump and,control,display ratio,hole,pseudo-haptic,texture},
pages = {239--246},
title = {{Feeling bumps and holes without a haptic interface: the perception of pseudo-haptic textures}},
memo = {http://dl.acm.org/citation.cfm?id=985723},
volume = {6},
year = {2004}
}

@inproceedings{6775491,
author = {Kokubun, A and Ban, Y and Narumi, T and Tanikawa, T and Hirose, M},
booktitle = {Haptics Symposium (HAPTICS), 2014 IEEE},
doi = {10.1109/HAPTICS.2014.6775491},
file = {:Users/Ujitoko/Library/Application Support/Mendeley Desktop/Downloaded/Kokubun et al. - 2014 - Representing normal and shearing forces on the mobile device with visuo-haptic interaction and a rear touch inte.pdf:pdf},
keywords = {haptic interfaces;mobile computing;touch sensitive},
pages = {415--420},
title = {{Representing normal and shearing forces on the mobile device with visuo-haptic interaction and a rear touch interface}},
year = {2014}
}

@article{Kimura2012,
abstract = {In most of the research on pseudo-haptic feedback, subjects' hands are on the desk and the visual image is provided from a monitor placed in front of them. The setup easily induces sensory conflicts for pseudo-haptic feedback between visual and haptic perception. However, subjects rarely see simultaneously their hand in motion and in a visual display. We report here our preliminary study on pseudo-haptic feedback related to tactile perception of softness. In the study, subjects hold a hand-held display with pressure sensors. A virtual object shown on the display screen changes shape according to pressures from the subject's squeezing of the device. In this configuration, subjects are able to see their hand and the visual display at same time. We also describe the preliminary experimental results confirming the feasibility of our system and its applicability in investigating haptic pseudo-haptic.},
author = {Kimura, Takashi and Nojima, Takuya},
doi = {10.1007/978-3-642-31404-9_36},
file = {:Users/Ujitoko/Library/Application Support/Mendeley Desktop/Downloaded/Kimura, Nojima - 2012 - Pseudo-haptic feedback on softness induced by grasping motion.pdf:pdf},
isbn = {978-3-642-31403-2},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Pseudo-haptic feedback,hand squeeze,softness},
number = {PART 2},
pages = {202--205},
title = {{Pseudo-haptic feedback on softness induced by grasping motion}},
volume = {7283 LNCS},
year = {2012}
}

@inproceedings{Lockwood:2012:FWM:2422356.2422364,
address = {Aire-la-Ville, Switzerland, Switzerland},
author = {Lockwood, Noah and Singh, Karan},
booktitle = {Proceedings of the ACM SIGGRAPH/Eurographics Symposium on Computer Animation},
isbn = {978-3-905674-37-8},
pages = {43--52},
publisher = {Eurographics Association},
series = {SCA '12},
title = {{Finger Walking: Motion Editing with Contact-based Hand Performance}},
url = {http://dl.acm.org/citation.cfm?id=2422356.2422364},
year = {2012}
}

@inproceedings{Fernando:2009:OMB:1665137.1665198,
address = {New York, NY, USA},
author = {Fernando, Charith Lasantha and Igarashi, Takeo and Inami, Masahiko and Sugimoto, Maki and Sugiura, Yuta and Withana, Anusha Indrajith and Gota, Kakehi},
booktitle = {ACM SIGGRAPH ASIA 2009 Art Gallery {\&}{\#}38; Emerging Technologies: Adaptation},
doi = {10.1145/1665137.1665198},
isbn = {978-1-60558-878-0},
pages = {79},
publisher = {ACM},
series = {SIGGRAPH ASIA '09},
title = {{An Operating Method for a Bipedal Walking Robot for Entertainment}},
url = {http://doi.acm.org/10.1145/1665137.1665198},
year = {2009}
}

@article{Ujitoko2011,
author = {Ujitoko, Yusuke and Hirota, Koichi},
file = {:Users/Ujitoko/Library/Application Support/Mendeley Desktop/Downloaded/Ujitoko, Hirota - 2011 - Application of the Locomotion Interface using Anthropomorphic Finger Motion.pdf:pdf},
keywords = {finger motion,ground instability,locomotion,multimodality},
title = {{Application of the Locomotion Interface using Anthropomorphic Finger Motion}},
year = {2011}
}

@Misc{yubitoko,
author = {},
title = {Yubi-Toko},
note = "\url{https://itunes.apple.com/jp/app/yubi-toko/id1038433623?mt=8
}",
}



@article{Rocchesso2015,
author = {Rocchesso, D. and {Delle Monache}, S. and Papetti, S.},
doi = {10.1016/j.ijhcs.2015.07.005},
file = {:Users/Ujitoko/Library/Application Support/Mendeley Desktop/Downloaded/Rocchesso, Delle Monache, Papetti - 2015 - Multisensory texture exploration at the tip of the pen(2).pdf:pdf},
memo = {10715819},
journal = {International Journal of Human-Computer Studies},
keywords = {Multisensory textures,Pen-based interaction,Pseudo-haptics,Sonic interaction design,pen-based interaction},
pages = {1--10},
publisher = {Elsevier},
title = {{Multisensory texture exploration at the tip of the pen}},
memo = {http://linkinghub.elsevier.com/retrieve/pii/S1071581915001238},
year = {2015}
}

@misc{Okamoto2013,
abstract = {This paper reviews studies on the tactile dimensionality of physical properties of materials in order to determine a common structure for these dimensions. Based on the commonality found in a number of studies and known mechanisms for the perception of physical properties of textures, we conclude that tactile textures are composed of three prominent psychophysical dimensions that are perceived as roughness/smoothness, hardness/softness, and coldness/warmness. The roughness dimension may be divided into two dimensions: macro and fine roughness. Furthermore, it is reasonable to consider that a friction dimension that is related to the perception of moistness/dryness and stickiness/slipperiness exists. Thus, the five potential dimensions of tactile perception are macro and fine roughness, warmness/coldness, hardness/softness, and friction (moistness/dryness, stickiness/slipperiness). We also summarize methods such as psychological experiments and mathematical approaches for structuring tactile dimensions and their limitations.},
author = {Okamoto, Shogo and Nagano, Hikaru and Yamada, Yoji},
booktitle = {IEEE Transactions on Haptics},
doi = {10.1109/ToH.2012.32},
isbn = {1939-1412},
issn = {19391412},
keywords = {Factor analysis,Multidimensional scaling,Sensory evaluation},
number = {1},
pages = {81--93},
pmid = {24808270},
title = {{Psychophysical dimensions of tactile perception of textures}},
volume = {6},
year = {2013}
}

@inproceedings{Maeno2006,
abstract = {In the present study, tactile display of surface texture by use of amplitude modulation of ultrasonic vibration is developed. First, systems are constructed to display artificial tactile sensation using ultrasonic vibrator. Then, sensory evaluation experiments are conducted to confirm that output stimulations in response to hand velocity is effective to realize an artificial tactile sensation. Next, it is confirmed that the proposed method to display roughness of a real cloth was more effective than existing method. Then, we evaluated the tactile sensation of a real cloth and a tactile display quantitatively using SD (semantic differential) method. As a result, at the evaluation item on roughness, the correlation coefficients between a real cloth and an artificial tactile sensation using proposed method was quite high. In conclusion, it is confirmed that realistic surface texture can be displayed by use of amplitude modulation of ultrasonic vibration},
author = {Maeno, Takashi and Otokawa, Kayo and Konyo, Masashi},
booktitle = {Proceedings of the IEEE Ultrasonics Symposium},
memo = {10.1109/ULTSYM.2006.29},
isbn = {1424402018},
issn = {10510117},
keywords = {Amplitude modulation,Tactile display,Texture,Ultrasonic vibration},
pages = {62--65},
title = {{Tactile display of surface texture by use of amplitude modulation of ultrasonic vibration}},
volume = {1},
year = {2006}
}

@article{Wiertlewski2011,
abstract = {The tactual scanning of five naturalistic textures was recorded with an apparatus that is capable of measuring the tangential interaction force with a high degree of temporal and spatial resolution. The resulting signal showed that the transformation from the geometry of a surface to the force of traction and, hence, to the skin deformation experienced by a finger is a highly nonlinear process. Participants were asked to identify simulated textures reproduced by stimulating their fingers with rapid, imposed lateral skin displacements as a function of net position. They performed the identification task with a high degree of success, yet not perfectly. The fact that the experimental conditions eliminated many aspects of the interaction, including low-frequency finger deformation, distributed information, as well as normal skin movements, shows that the nervous system is able to rely on only two cues: amplitude and spectral information. The examination of the spatial spectrograms of the imposed lateral skin displacement revealed that texture could be represented spatially, despite being sensed through time and that these spectrograms were distinctively organized into what could be called spatial formants. This finding led us to speculate that the mechanical properties of the finger enables spatial information to be used for perceptual purposes in humans with no distributed sensing, which is a principle that could be applied to robots. {\textcopyright} 2011 IEEE.},
author = {Wiertlewski, Michael and Lozada, Jos{\'{e}} and Hayward, Vincent},
doi = {10.1109/TRO.2011.2132830},
isbn = {1552-3098},
issn = {15523098},
journal = {IEEE Transactions on Robotics},
keywords = {Haptic interfaces,surface texture,tactile sensor,virtual reality},
number = {3},
pages = {461--472},
title = {{The spatial spectrum of tangential skin displacement can encode tactual texture}},
volume = {27},
year = {2011}
}

@inproceedings{Culbertson2012,
abstract = {Abstract Dragging a tool across a textured object creates rich high-frequency vibrations that distinctly convey the physical interaction between the tool tip and the object surface. Varying one's scanning speed and normal force alters these vibrations, but it does not change the ... $\backslash$n},
author = {Culbertson, Heather and Romano, Joseph M. and Castillo, Pablo and Mintz, Max and Kuchenbecker, Katherine J.},
booktitle = {Proceedings of the IEEE Haptics Symposium},
memo = {10.1109/HAPTIC.2012.6183819},
isbn = {9781467308090},
issn = {19391412},
pages = {385--391},
title = {{Refined methods for creating realistic haptic virtual textures from tool-mediated contact acceleration data}},
year = {2012}
}

@InProceedings{ganHaptics,
author="Ujitoko, Yusuke
and Ban, Yuki",
editor="Prattichizzo, Domenico
and Shinoda, Hiroyuki
and Tan, Hong Z.
and Ruffaldi, Emanuele
and Frisoli, Antonio",
title="Vibrotactile Signal Generation from Texture Images or Attributes Using Generative Adversarial Network",
booktitle="Haptics: Science, Technology, and Applications",
year="2018",
publisher="Springer International Publishing",
address="Cham",
pages="25--36",
abstract="Providing vibrotactile feedback that corresponds to the state of the virtual texture surfaces allows users to sense haptic properties of them. However, hand-tuning such vibrotactile stimuli for every state of the texture takes much time. Therefore, we propose a new approach to create models that realize the automatic vibrotactile generation from texture images or attributes. In this paper, we make the first attempt to generate the vibrotactile stimuli leveraging the power of deep generative adversarial training. Specifically, we use conditional generative adversarial networks (GANs) to achieve generation of vibration during moving a pen on the surface. The preliminary user study showed that users could not discriminate generated signals and genuine ones and users felt realism for generated signals. Thus our model could provide the appropriate vibration according to the texture images or the attributes of them. Our approach is applicable to any case where the users touch the various surfaces in a predefined way.",
isbn="978-3-319-93399-3"
}

@INPROCEEDINGS{banCurvature,
author={Y. Ban and T. Kajinami and T. Narumi and T. Tanikawa and M. Hirose},
booktitle={Proceedings of the IEEE Haptics Symposium},
title={Modifying an identified curved surface shape using pseudo-haptic effect},
year={2012},
volume={},
number={},
pages={211-216},
keywords={computational geometry;data visualisation;haptic interfaces;human computer interaction;shape recognition;touch (physiological);virtual reality;curved surface shape identification;identified curved surface shape modification;pointing finger;pseudohaptic effect;touch sensation;user hand visual representation;varying shape virtual objects;video see-through system;visuo-haptic interaction;visuohaptic system;Educational institutions;Electronic mail;Haptic interfaces;Information science;Monitoring;Shape;Visualization;Identified Shape Modification;Pseudo-haptics;Visuo-haptic interaction},
memo={10.1109/HAPTIC.2012.6183793},
ISSN={2324-7347},
memo={March},
}

@InProceedings{banAngle,
author="Ban, Yuki
and Kajinami, Takashi
and Narumi, Takuji
and Tanikawa, Tomohiro
and Hirose, Michitaka",
memo="Isokoski, Poika and Springare, Jukka",
title="Modifying an Identified Angle of Edged Shapes Using Pseudo-haptic Effects",
booktitle="Proceedings of the International Conference on Haptics: Perception, Devices, Mobility, and Communication",
year="2012",
memo="Springer Berlin Heidelberg",
memo="Berlin, Heidelberg",
pages="25--36",
abstract="In this paper, we focus on modifying the identification of an angle of edges when touching it with a pointing finger, by displacing the visual representation of the user's hand in order to construct a novel visuo-haptic system. We compose a video see-through system, which enables us to change the perception of the shape of an object a user is visually touching, by displacing the visual representation of the user's hand as if s/he was touching the visual shape, when in actuality s/he is touching another shape.",
isbn="978-3-642-31401-8"
}

@article{banSize,
abstract = {Abstract In this study, we aim to construct a perception-based shape display system to provide users with the sensation of touching virtual objects of varying shapes using only a simple mechanism. Thus far, we have proved that identified curved surface shapes or edge angles can be modified by displacing the visual representation of the user's hand. However, using this method, we cannot emulate multifinger touch, because of spatial unconformity. To solve this problem, we focus on modifying the identification of shapes using two fingers by deforming the visual representation of the user's hand. We devised a video see-through system that enables us to change the perceived shape of an object that a user is touching visually. The visual representation of the user's hand is deformed as if the user were handling a visual object; however, the user is actually handling an object of a different shape. Using this system, we conducted two experiments to investigate the effects of visuo-haptic interaction and evaluate its effectiveness. One is an investigation on the modification of size perception to confirm that the fingers did not stroke the shape but only touched it statically. The other is an investigation on the modification of shape perception for confirming that the fingers dynamically stroked the surface of the shape. The results of these experiments show that the perceived sizes of objects handled using a thumb and other finger(s) could be modified if the difference between the size of physical and visual stimuli was in the −40{\%} to 35{\%} range. In addition, we found that the algorithm can create an effect of shape perception modification when users stroke the shape with multiple fingers.},
author = {Ban, Yuki and Narumi, Takuji and Tanikawa, Tomohiro and Hirose, Michitaka},
memo = {10.1162/PRES_a_00154},
issn = {10547460},
journal = {Presence: Teleoperators and Virtual Environments},
number = {3},
pages = {255--270},
title = {{Modifying perceived size of a handled object through hand image deformation1}},
volume = {22},
year = {2013}
}

@article{Argelaguet:2013:EIP:2506206.2501599,
 author = {Argelaguet, Ferran and J\'{a}uregui, David Antonio G\'{o}mez and Marchal, Maud and L{\'e}cuyer, Anatole},
 title = {Elastic Images: Perceiving Local Elasticity of Images Through a Novel Pseudo-haptic Deformation Effect},
 journal = {ACM Transactions on Applied Perception},
 memo = {August 2013},
 volume = {10},
 number = {3},
 memo = {aug},
 year = {2013},
 issn = {1544-3558},
 pages = {1--14},
 articleno = {17},
 numpages = {14},
 url = {http://doi.acm.org/10.1145/2501599},
 memo = {10.1145/2501599},
 acmid = {2501599},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Pseudo-haptic, elasticity, stiffness, texture},
}


@inproceedings{Minamizawa2012,
abstract = {There has been many haptic devices proposed so far, but most of them are still in emerging stage. To attract the interest of potential users of haptics such as designers, educators, and students, it is necessary to provide easy-to-make and easy-to-use haptic device. We then developed an introductory haptic device named "TECHTILE toolkit". Current prototype is composed of haptic recorder, haptic reactor, and signal amplifier that is optimized to present not only zone of audibility but also low frequency vibrotactile sensation. This toolkit is intuitive to use and can be developed with low cost. We are currently holding a number of workshops to confirm that this device is suitable as an educational tool for learning possible applications of haptics design.},
author = {Minamizawa, Kouta and Kakehi, Yasuaki and Nakatani, Masashi and Mihara, Soichiro and Tachi, Susumu},
booktitle = {Proceedings of the Virtual Reality International Conference},
memo = {10.1145/2331714.2331745},
isbn = {9781450312431},
keywords = {haptic media,multisensory communication,tactile display,tactile sensor,vibrotactile sensation},
pages = {1},
title = {{TECHTILE toolkit}},
memo = {http://dl.acm.org/citation.cfm?doid=2331714.2331745},
year = {2012}
}


@article{Strese2017,
abstract = {{\textcopyright} 2017 IEEE. When a tool is tapped on or dragged over an object surface, vibrations are induced in the tool, which can be captured using acceleration sensors. The tool-surface interaction additionally creates audible sound waves, which can be recorded using microphones. Features extracted from camera images provide additional information about the surfaces. We present an approach for tool-mediated surface classification that combines these signals and demonstrate that the proposed method is robust against variable scan-time parameters. We examine freehand recordings of 69 textured surfaces recorded by different users and propose a classification system that uses perception-related features, such as hardness, roughness, and friction; selected features adapted from speech recognition, such as modified cepstral coefficients applied to our acceleration signals; and surface texture-related image features. We focus on mitigating the effect of variable contact force and exploration velocity conditions on these features as a prerequisite for a robust machine-learning-based approach for surface classification. The proposed system works without explicit scan force and velocity measurements. Experimental results show that our proposed approach allows for successful classification of textured surfaces under variable freehand movement conditions, exerted by different human operators. The proposed subset of six features, selected from the described sound, image, friction force, and acceleration features, leads to a classification accuracy of 74 percent in our experiments when combined with a Naive Bayes classifier.},
author = {Strese, Matti and Schuwerk, Clemens and Iepure, Albert and Steinbach, Eckehard},
memo = {10.1109/TOH.2016.2625787},
issn = {19391412},
journal = {IEEE Transactions on Haptics},
keywords = {Tool-mediated surface classification,feature-based surface material recognition,multimodal surface classification},
number = {2},
pages = {226--239},
title = {{Multimodal Feature-Based Surface Material Classification}},
volume = {10},
year = {2017}
}


@article{Okamura1998,
abstract = {Vibrations can significantly enhance touch perception for virtual$\backslash$nenvironment applications with minimal design complexity and cost. In$\backslash$norder to create realistic vibrotactile feedback, we collected$\backslash$nvibrations, forces, and velocities during various tasks executed with a$\backslash$nstylus: tapping on materials, stroking textures, and puncturing$\backslash$nmembranes. Empirical models were fit to these waveforms and a library of$\backslash$nmodel parameters was compiled. These models simulated tasks involving$\backslash$nsimultaneous display of forces and vibrations on a high-bandwidth$\backslash$nforce-feedback joystick. Vibration feedback adds little complexity to$\backslash$nvirtual environment algorithms. Human subjects interacting with the$\backslash$nsystem showed improved execution and perception when performing surface$\backslash$nfeature discrimination tasks},
author = {Okamura, a.M. M and Dennerlein, J.T. T and Howe, R.D. D},
doi = {10.1109/ROBOT.1998.677050},
isbn = {0-7803-4300-X},
issn = {1050-4729},
journal = {Robotics and Automation, 1998. Proceedings. 1998 IEEE International Conference on},
keywords = {feedback,high-bandwidth,vibrations,virtual reality},
number = {May},
pages = {674--679 vol.1},
title = {{Vibration feedback models for virtual environments}},
volume = {1},
year = {1998}
}


@inproceedings{5356133,
author = {Guruswamy, V L and Lang, J and Lee, W S},
booktitle = {2009 IEEE International Workshop on Haptic Audio visual Environments and Games},
doi = {10.1109/HAVE.2009.5356133},
keywords = {IIR filters;feedback;haptic interfaces;image textu},
pages = {105--110},
title = {{Modelling of haptic vibration textures with infinite-impulse-response filters}},
year = {2009}
}


@inproceedings{Shin2015,
author = {Shin, Sunghwan and Osgouei, Reza Haghighi and Kim, Ki Duk and Choi, Seungmoon},
booktitle = {IEEE World Haptics Conference, WHC 2015},
memo = {10.1109/WHC.2015.7177703},
isbn = {9781479966240},
pages = {131--138},
title = {{Data-driven modeling of isotropic haptic textures using frequency-decomposed neural networks}},
year = {2015},
}


@inproceedings{Ujitoko,
 author = {Ujitoko, Yusuke and Ban, Yuki},
 title = {Vibrotactile Signal Generation from Texture Images or Attributes using Generative Adversarial Network},
 booktitle = {Proceedings of the EuroHaptics 2018}
}

@inproceedings{Tashiro2009,
abstract = {This paper presents a displaying method of button like click feeling using ultrasonic vibration with amplitude of a few micrometers. Artificial click feeling is displayed by recreating rapid change in force arising from buckling of a mechanical push button utilizing squeeze film effect. First, important factors for displaying click feeling were extracted by analyzing the relationship among force-stroke curve of mechanical buttons and perceived click feeling. Then, click feeling display system was constructed. In the system, stimulation are applied to the operators at both buckling and restitution point. Finally, by conducting several sensory evaluation experiments, it was verified that button like feeling can be displayed without recreating the stroke of mechanical buttons by use of ultrasonic vibration. It was also verified that various artificial click feeling can be displayed by controlling the multiple parameters of the system.},
author = {Tashiro, Kaoru and Shiokawa, Yuta and Aono, Tomotake and Maeno, Takashi},
booktitle = {Proceedings of the Joint EuroHaptics Conference and Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems, World Haptics},
memo = {10.1109/WHC.2009.4810877},
isbn = {9781424438587},
keywords = {Force feedback,Tactile display,Ultrasonic vibrator},
pages = {1--6},
title = {{Realization of button click feeling by use of ultrasonic vibration and force feedback}},
year = {2009}
}


@article{Rock1964,
abstract = {Observers were presented with an object whose visual shape, because of optical distortion, differed considerably from its tactual shape. After simultaneously grasping and viewing the object, the observers were required to indicate their impression of it by drawing it or by matching another object to it. The results reveal that vision is strongly dominant, often without the observer's being aware of a conflict.},
author = {Rock, Irvin and Victor, Jack},
memo = {10.1126/science.143.3606.594},
isbn = {0036-8075},
issn = {00368075},
journal = {Science},
number = {3606},
pages = {594--596},
pmid = {14080333},
title = {{Vision and touch: An experimentally created conflict between the two senses}},
volume = {143},
year = {1964}
}

@article{Lederman1981,
abstract = {Three experiments were performed involving the perception of surface texture. Experiment 1 indicated that when vision and touch are presented with discrepant information concerning texture, the two senses appear to weight the information about equally. Moreover, Experiment 2 showed that using touch, vision, or touch and vision, subjects performed a texture identification task with comparable matching accuracy and precision. Experiment 3 demonstrated that using the same three modes, subjects performed a magnitude estimation task similarly, in terms of magnitude estimates of roughness, the rates of growth of perceived roughness, and response precision. The comparability of the two senses in texture-related tasks may underlie the relatively equal compromise between discrepant sources of texture information demonstrated in Experiment (modality superiority interpretation). Such a compromise is somewhat different from that commonly reported in the sensory conflict literature. The relative weighting of multiple sources of sensory information about surface texture was also considered in terms of a directed-attention interpretation of intersensory organization.},
author = {Lederman, Susan J. and Abbott, Susan G.},
memo = {10.1037/0096-1523.7.4.902},
isbn = {0096-1523},
issn = {00961523},
journal = {Journal of Experimental Psychology: Human Perception and Performance},
keywords = {discrepant sources of touch {\&},vision information, intersensory organization in texture perception, 18-40 yr old college students},
number = {4},
pages = {902--915},
pmid = {6457101},
title = {{Texture perception: Studies of intersensory organization using a discrepancy paradigm, and visual versus tactual psychophysics}},
volume = {7},
year = {1981}
}

@article{Heller1982,
abstract = {In three experiments, subjects were required to make texture judgments about abrasive surfaces. Touch and vision provided comparable levels of performance when observers at{\textperiodcentered} tempted to select the smoothest of three surfaces, but bimodal visual and tactual input led to greater accuracy. The superiority of bimodal perception was ascribed to visual guidance of tactual exploration. The elimination of visual texture cues did not impair bimodal performance if vision of hand movements were permitted. It is suggested that touch may preempt vision when both sources of texture information are simultaneously available. The results support the notion that perception is normally multimodal, since restriction of the observer to either sense in isolation produces lower levels of performance. In 1891, Fraser bemoaned both the bias toward vi-sual research in psychology and the lack of investi-gation of the sense of touch. It has often been as-sumed that people are primarily visual and that the other senses are of secondary importance, and even that vision is better than touch and a "higher" sense, as Thomas Reid claimed when he said, "Of the five senses, sight is without doubt the noblest. The evi-dence of reason is called seeing, not feeling, smelling,},
author = {Heller, Morton A.},
memo = {10.3758/BF03202657},
isbn = {1532-5962$\backslash$r0031-5117},
issn = {00315117},
journal = {Perception {\&} Psychophysics},
number = {4},
pages = {339--344},
pmid = {7110887},
title = {{Visual and tactual texture perception: Intersensory cooperation}},
volume = {31},
year = {1982}
}

@InProceedings{Tatezono2009,
abstract = {We propose a haptic feedback system for an arm in order to obtain the sensation of stiffness and the boundary of virtual objects. Powerful haptic displays are large and heavy, interfering with movement in the virtual environment. Here, we focus on an illusion called pseudo-haptic feedback, which provides the results of haptic feedback using only visual impressions. Since pseudo-haptic feedback is known to be inappropriate for applications requiring strong force, a combination of pseudo-haptic feedback and real haptic feedback is proposed for a compact haptic display. This study examines the effectiveness of this combination by comparing the stiffness of two walls. Pseudo-haptic and real haptic feedbacks are applied to one wall, and only real haptic feedback is applied to the other wall. The results verify that the magnitude of the force perceived with the application of a combination of pseudo-haptic and real haptic feedbacks is greater than that of the force perceived by the application of only real haptic feedback.},
author = {Tatezono, M. and Sato, K. and Minamizawa, K. and Nii, H. and Kawakami, N. and Tachi, S.},
file = {:Users/Ujitoko/Library/Application Support/Mendeley Desktop/Downloaded/Tatezono et al. - 2009 - Effect of haptic feedback on pseudo-haptic feedback for arm display.pdf:pdf},
isbn = {978-4-907764-34-0},
booktitle = {Proceedings of the International Conference on Control, Automation and Systems},
keywords = {haptic feedback,pseudo-haptic,virtual reality},
title = {{Effect of haptic feedback on pseudo-haptic feedback for arm display}},
year = {2009}
}

@inproceedings{Kokubun,
author = {Kokubun, A and Ban, Y and Narumi, T and Tanikawa, T and Hirose, M},
booktitle = {Haptics Symposium (HAPTICS), 2014 IEEE},
doi = {10.1109/HAPTICS.2014.6775491},
file = {:Users/Ujitoko/Library/Application Support/Mendeley Desktop/Downloaded/Kokubun et al. - 2014 - Representing normal and shearing forces on the mobile device with visuo-haptic interaction and a rear touch inte.pdf:pdf},
keywords = {haptic interfaces;mobile computing;touch sensitive},
pages = {415--420},
title = {{Representing normal and shearing forces on the mobile device with visuo-haptic interaction and a rear touch interface}},
year = {2014}
}

@Misc{online_demo,
author = {Yusuke, Ujitoko and Yuki, Ban},
title = {Online demonstration page of this study},
note = "\url{https://pseudotexture.herokuapp.com/}",
}


@inproceedings{Asano2012,
abstract = {In this study, we developed vibrotactile display methods that can assist designers in product design. In order to achieve realistic sensations required for such designing purposes, we used real materials such as cloth, paper, wood, and leather and applied vibrotactile stimuli to modify the roughness sensations of these materials. This approach allowed us to present textures of various virtual materials with a strong sense of reality. We verified that our proposed methods could selectively modify the fine and macro-roughness sensations of real materials. The methods are expected to aid product designers in deciding tactile sensations suitable for their products.},
author = {Asano, Shuhei and Okamoto, Shogo and Matsuura, Yoichiro and Nagano, Hikaru and Yamada, Yoji},
booktitle = {Proceedings of the IEEE International Workshop on Robot and Human Interactive Communication},
memo = {10.1109/ROMAN.2012.6343880},
isbn = {9781467346054},
issn = {1944-9445},
keywords = {Surface roughness,Vibrotactile texture display},
pages = {1001--1006},
title = {{Vibrotactile display approach that modifies roughness sensations of real textures}},
year = {2012}
}

@article{Asano2015,
abstract = {We have developed a texture display system that modifies the perceived roughness of textured surfaces via a voice coil actuator worn on the finger. To increase the roughness sensations, the vibrotactile stimuli from the actuator simulate the skin deformations that are activated when a wavy surface is scanned. Conversely, to decrease the roughness sensations of the textured surface, a high-frequency vibrotactile stimulus offsets the activity levels of tactile mechanoreceptors. This offset suppresses the perceived roughness of the surfaces being touched, with increase in the offset correlating with increase in the feeling of smoothness of the surfaces. We conducted an experiment in which we tested the effects of these two types of vibrotactile stimulation on grating roughness specimens, with subjective responses acquired from eight participants via the magnitude estimation method. The results obtained indicate that our method selectively increases and decreases the roughness felt. The intention is for the technique to be used to develop an augmented reality device for textures.},
author = {Asano, Shuhei and Okamoto, Shogo and Yamada, Yoji},
memo = {10.1109/THMS.2014.2376519},
issn = {21682291},
journal = {IEEE Transactions on Human-Machine Systems},
keywords = {Augmented reality,haptic device,mechanoreceptors,roughness,texture,vibrotactile stimulation},
number = {3},
pages = {393--398},
title = {{Vibrotactile stimulation to increase and decrease texture roughness}},
volume = {45},
year = {2015}
}

@article{Miyaoka1999,
abstract = {The purpose of this study was to evaluate the ability of touch to discriminate fine-surface textures and to suggest possible mechanisms of the discriminations. Two experiments were performed. In experiment 1, aluminum-oxide abrasive papers were adopted as stimuli, and psychometric functions and difference thresholds were determined in fine-surface-texture discrimination tasks. The grit values of abrasive papers were 400, 600, 1200, 2000, 3000, 4000, and 8000; corresponding average particle sizes were 40, 30, 12, 9, 5, 3, and 1 micron, respectively. Ten subjects participated in experiment 1. The difference thresholds obtained in experiment 1 were between 2.4 and 3.3 microns. In experiment 2, the tasks were discriminations of ridge height. The cross sections of the etched ridges were rectangular and the ridge heights were 6.3, 7.0, 8.6, 10.8, 12.3, 18.5, and 25.0 microns. Six subjects participated in experiment 2. The difference thresholds in experiment 2 were between 0.95 and 2.0 microns. It was reasoned, based on the Weber fraction values calculated from the difference thresholds and on the limit of neural information-processing ability of humans, that the subjects discriminate fine roughness only from the amplitude information presented in surface unevenness.},
author = {Miyaoka, Tetsu and Mano, Tadaaki and Ohka, Masahiro},
memo = {10.1121/1.426852},
isbn = {0001-4966 (Print)},
issn = {0001-4966},
journal = {Journal of the Acoustical Society of America},
number = {4},
pages = {2485--2492},
pmid = {10212429},
title = {{Mechanisms of fine-surface-texture discrimination in human tactile sensation}},
url = {http://asa.scitation.org/doi/10.1121/1.426852},
volume = {105},
year = {1999}
}

@article{Bensmaia2003,
abstract = {The Pacinian channel has been implicated in the perception of fine textures (Hollins et al., Somatosens Mot Res 18: 253-262, 2001a). In the present study, we investigate candidate codes for Pacinian-mediated roughness perception. We use a Hall effect transducer to record the vibrations elicited in the skin when a set of textured surfaces is passively presented to the index finger. The peak frequency of the vibrations is found to decrease systematically as spatial period increases. The power of the vibrations--weighted according to the spectral sensitivity of the Pacinian system--increases with spatial period for all but the coarsest surfaces. By varying the scanning velocity, we manipulate the temporal and intensive characteristics of the texture-induced vibrations and assess the effect of the manipulation on perceived roughness. We find that doubling the scanning velocity does not result in the substantial decrease in roughness predicted by a frequency theory of vibrotactile roughness perception. On the other hand, the effects of speed on roughness match those of speed on power. We propose that the roughness of a fine surface (spatial period{\textless}200 microm) is a function of the Pacinian-weighted power of the vibrations it elicits.},
author = {Bensmaia, Sliman J. and Hollins, Mark},
doi = {10.1080/0899022031000083825},
isbn = {0899-0220 (Print)$\backslash$r0899-0220 (Linking)},
issn = {08990220},
journal = {Somatosensory and Motor Research},
keywords = {Pacinian,Power,Roughness,Texture,Vibration},
number = {1},
pages = {33--43},
pmid = {12745443},
title = {{The vibrations of texture}},
volume = {20},
year = {2003}
}

@article{Hollins2000,
abstract = {According to the duplex theory of tactile texture perception, detection of cutaneous vibrations produced when the exploring finger moves across a surface contributes importantly to the perception of fine textures. If this is true, a vibrating surface should feel different from a stationary one. To test this prediction, experiments were conducted in which subjects examined two identical surfaces, one of which was surreptitiously made to vibrate, and judged which of the two was smoother. In experiment 1, the vibrating surface was less and less often judged smoother as the amplitude of (150 Hz) vibration increased. The effect was comparable in subjects who realized the surface was vibrating and those who did not. Experiment 2 showed that different frequencies (150-400 Hz) were equally effective in eliciting the effect when equated in sensation level (dB SL). The results suggest that vibrotaction contributes to texture perception, and that, at least within the Pacinian channel, it does so by means of an intensity code.},
author = {Hollins, Mark and Fox, Aaron and Bishop, Carianne},
memo = {10.1068/p3044},
issn = {03010066},
journal = {Perception},
number = {12},
pages = {1455--1465},
pmid = {11257969},
title = {{Imposed vibration influences perceived tactile smoothness}},
volume = {29},
year = {2000}
}

@inproceedings{Hachisu2011,
abstract = {Musical video games that allow users to play expensive musical instruments in a virtual environment constitute one of the most popular genres in the field of video games. Recent developments in motion input technology have enabled users to play the instruments intuitively and immersively. However, output technology, in particular haptic feedback, is not as advanced as input technology. We believe that providing a haptic sensation enriches the content of musical video games since the results of the motion input are fed back. To enrich the haptic sensation, we propose a system for playing virtual chromatic percussion, where the haptic feedback changes according to the instrument, as well as the acoustic feedback. In this paper, we propose a system describing a novel stick type controller and pseudo-haptic feedback to enrich the haptic sensation of the content. We also present an application that provides a virtual environment for playing two chromatic percussion instruments, namely the xylophone and glockenspiel.},
author = {Hachisu, Taku and Cirio, Gabriel and Marchal, Maud and L{\'{e}}cuyer, Anatole and Kajimoto, Hiroyuki},
memo = {10.1145/2071423.2071448},
isbn = {978-1-4503-0827-4},
booktitle = {Proceedings of the International Conference on Advances in Computer Entertainment Technology},
keywords = {haptic illusion,haptic sensation,material,musical video game,vibration},
pages = {20:1--20:5},
title = {{Virtual Chromatic Percussions Simulated by Pseudo-haptic and Vibrotactile Feedback}},
url = {http://doi.acm.org/10.1145/2071423.2071448},
year = {2011}
}

@article{doi:10.1146/annurev-control-060117-105043,
author = {Culbertson, Heather and Schorr, Samuel B. and Okamura, Allison M.},
title = {Haptics: The Present and Future of Artificial Touch Sensation},
journal = {Annual Review of Control, Robotics, and Autonomous Systems},
volume = {1},
number = {1},
pages = {385-409},
year = {2018},
memo = {10.1146/annurev-control-060117-105043},
memo = {https://doi.org/10.1146/annurev-control-060117-105043},
memo = {https://doi.org/10.1146/annurev-control-060117-105043},
abstract = { This article reviews the technology behind creating artificial touch sensations and the relevant aspects of human touch. We focus on the design and control of haptic devices and discuss the best practices for generating distinct and effective touch sensations. Artificial haptic sensations can present information to users, help them complete a task, augment or replace the other senses, and add immersiveness and realism to virtual interactions. We examine these applications in the context of different haptic feedback modalities and the forms that haptic devices can take. We discuss the prior work, limitations, and design considerations of each feedback modality and individual haptic technology. We also address the need to consider the neuroscience and perception behind the human sense of touch in the design and control of haptic devices. }
}

@ARTICLE{Culbertson2017,
author={H. Culbertson and K. J. Kuchenbecker},
journal={IEEE Transactions on Haptics},
title={Importance of Matching Physical Friction, Hardness, and Texture in Creating Realistic Haptic Virtual Surfaces},
year={2017},
volume={10},
number={1},
pages={63-74},
keywords={haptic interfaces;virtual reality;haptic virtual surfaces;tactile sensation;kinesthetic sensation;haptic impression;user experience;haptic models;surface friction;tapping transients;texture vibrations;SensAble Phantom Omni haptic interface;Tactile Labs Haptuator;human-subject study;Haptic interfaces;Friction;Surface texture;Rendering (computer graphics);Rough surfaces;Surface roughness;Vibrations;Virtual reality;data-driven modeling;high-frequency vibrations;haptic texture rendering;force feedback;Algorithms;Computer Simulation;Female;Friction;Hardness;Humans;Male;Models, Theoretical;Physical Stimulation;Robotics;Surface Properties;Touch;User-Computer Interface;Vibration},
memo={10.1109/TOH.2016.2598751},
ISSN={1939-1412},
memo={Jan},
}

@inproceedings{Strohmeier:2017:GHT:3025453.3025812,
 author = {Strohmeier, Paul and Hornb{\ae}k, Kasper},
 title = {Generating Haptic Textures with a Vibrotactile Actuator},
 booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
 memo = {CHI '17},
 year = {2017},
 isbn = {978-1-4503-4655-9},
 location = {Denver, Colorado, USA},
 pages = {4994--5005},
 numpages = {12},
 url = {http://doi.acm.org/10.1145/3025453.3025812},
 memo = {10.1145/3025453.3025812},
 acmid = {3025812},
 memo = {ACM},
 memo = {New York, NY, USA},
 keywords = {haptic feedback, magnitude estimation, texture perception},
}


@InProceedings{Issartel2015PerceivingMI,
  title={Perceiving mass in mixed reality through pseudo-haptic rendering of Newton's third law},
  author={Paul Issartel and Florimond Gu{\'e}niat and Sabine Coquillart and Mehdi Ammi},
  booktitle={Proceedings of the IEEE Virtual Reality},
  year={2015},
  pages={41-46}
}

@article{Jauregui:2014:TPA:2608067.2608146,
 author = {Jauregui, David Antonio Gomez and Argelaguet, Ferran and Olivier, Anne-Helene and Marchal, Maud and Multon, Franck and Lecuyer, Anatole},
 title = {Toward "Pseudo-Haptic Avatars": Modifying the Visual Animation of Self-Avatar Can Simulate the Perception of Weight Lifting},
 journal = {IEEE Transactions on Visualization and Computer Graphics},
 issue_date = {April 2014},
 volume = {20},
 number = {4},
 memo = {apr},
 year = {2014},
 issn = {1077-2626},
 pages = {654--661},
 numpages = {8},
 url = {https://doi.org/10.1109/TVCG.2014.45},
 memo = {10.1109/TVCG.2014.45},
 acmid = {2608146},
 publisher = {IEEE Educational Activities Department},
 address = {Piscataway, NJ, USA},
 keywords = {Avatars,Animation,Visualization,Wrist,Virtual environments,Joints,Visual effects,Self-animated avatar, avatar-based physical interaction, perception of motion dynamics, pseudo-haptic feedback},
}

@article{Hoshi:2010:NTD:1907654.1908041,
 author = {Hoshi, Takayuki and Takahashi, Masafumi and Iwamoto, Takayuki and Shinoda, Hiroyuki},
 title = {Noncontact Tactile Display Based on Radiation Pressure of Airborne Ultrasound},
 journal = {IEEE Transactions on Haptics},
 issue_date = {July 2010},
 volume = {3},
 number = {3},
 memo = {jul},
 year = {2010},
 issn = {1939-1412},
 pages = {155--165},
 numpages = {11},
 memo = {http://dx.doi.org/10.1109/TOH.2010.4},
 memo = {10.1109/TOH.2010.4},
 acmid = {1908041},
 publisher = {IEEE Computer Society Press},
 address = {Los Alamitos, CA, USA},
 keywords = {3D displays, Emerging technologies, Emerging technologies, haptic I/O, tactile displays, 3D displays, virtual reality., haptic I/O, tactile displays, virtual reality.},
}

@INPROCEEDINGS{Hasegawa2013,
author={K. Hasegawa and H. Shinoda},
booktitle={Proceedings of the IEEE World Haptics Conference},
title={Aerial display of vibrotactile sensation with high spatial-temporal resolution using large-aperture airborne ultrasound phased array},
year={2013},
volume={},
number={},
pages={31-36},
keywords={aircraft displays;haptic interfaces;quantisation (signal);radiation pressure;skin;spatiotemporal phenomena;tactile sensors;ultrasonic transducers;vibrations;vibrotactile aerial display sensation;spatiotemporal resolution;aperture airborne ultrasound phased array;vibrotactile sensation generation;human skin;focused airborne ultrasound radiation pressure;ultrasound transducer units;vibrotactile stimuli;arbitrary spatial point;quantization;radiation pressure amplitude;size 1 m;time 0.5 ms;Ultrasonic imaging;Transducers;Arrays;Skin;Apertures;Field programmable gate arrays;Pressure measurement;Airborne Ultrasound;Vibrotactile Sensation;Whole-body Passive Tactile Display},
memo={10.1109/WHC.2013.6548380},
ISSN={},
memo={April},
}


@article{doi:10.1121/1.2715669,
author = {Mortimer,Bruce J. P.  and Zets,Gary A.  and Cholewiak,Roger W. },
title = {Vibrotactile transduction and transducers},
journal = {Journal of the Acoustical Society of America},
volume = {121},
number = {5},
pages = {2970-2977},
year = {2007},
memo = {10.1121/1.2715669},

URL = {
        https://doi.org/10.1121/1.2715669

},
eprint = {
        https://doi.org/10.1121/1.2715669

}

}


@article{doi:10.1080/00140139408964917,
author = { S.   Maeda  and  M. J.   Griffin },
title = {A comparison of vibrotactile thresholds on the finger obtained with different equipment},
journal = {Ergonomics},
volume = {37},
number = {8},
pages = {1391-1406},
year  = {1994},
publisher = {Taylor & Francis},
memo = {10.1080/00140139408964917},
memo ={PMID: 7925262},
URL = {
        https://doi.org/10.1080/00140139408964917
},
eprint = {
        https://doi.org/10.1080/00140139408964917
}
}

@ARTICLE{5722959,
author={C. Salisbury and R. B. Gillespie and H. Z. Tan and F. Barbagli and J. K. Salisbury},
journal={IEEE Transactions on Haptics},
title={What you can't feel won't hurt you: Evaluating haptic hardware using a haptic contrast sensitivity function},
year={2011},
volume={4},
number={2},
pages={134-146},
keywords={haptic interfaces;image texture;rendering (computer graphics);haptic hardware;haptic contrast sensitivity function;video projectors;human observers;texture rendering;voice coil motor;human detection thresholds;Haptic interfaces;Humans;Hardware;Vibrations;Force;Software;Accelerometers;Haptics;design;psychophysics;texture;evaluation of haptic devices;haptic contrast sensitivity function (HCSF).},
memo={10.1109/TOH.2011.5},
ISSN={1939-1412},
memo={April},}

@Inbook{Ehrenstein1999,
author="Ehrenstein, Walter H.
and Ehrenstein, Addie",
editor="Windhorst, Uwe
and Johansson, H{\aa}kan",
title="Psychophysical Methods",
bookTitle="Modern Techniques in Neuroscience Research",
year="1999",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="1211--1241",
abstract="When Fechner (1860/1966) introduced the new transdisciplinary research program of ``Psychophysik'',his goal was to present a scientific method of studying the relations between body and mind, or, to put it more precisely, between the physical and phenomenal worlds. The key idea underlying Fechner's psychophysics was that body and mind are just different reflections of the same reality. From an external, objective viewpoint we speak of processes in the brain (i.e., of bodily processes). Considering the same processes from an internalized, subjective viewpoint, we can speak of processes of the mind. In suggesting that processes of the brain are directly reflected in processes of the mind, Fechner anticipated one of the main goals of modern neuroscience, which is to establish correlations between neuronal (objective) and perceptual (subjective) events.",
isbn="978-3-642-58552-4",
memo="10.1007/978-3-642-58552-4_43",
memo="https://doi.org/10.1007/978-3-642-58552-4_43"
}

@InProceedings{Tactiped,
author="Pan{\"e}els, Sabrina
and Anastassova, Margarita
and Brunet, Lucie",
editor="Kotz{\'e}, Paula
and Marsden, Gary
and Lindgaard, Gitte
and Wesson, Janet
and Winckler, Marco",
title="TactiPEd: Easy Prototyping of Tactile Patterns",
booktitle="Human-Computer Interaction -- INTERACT 2013",
year="2013",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="228--245",
abstract="We present the design and evaluation of a tactile editor, TactiPEd for the rapid and easy prototyping of vibrotactile patterns. It is based on the graphical metaphor of the shape of the device, which is used for the tuning of the main tactile characteristics, including amplitude, frequency and duration of tactile sequences. The editor includes file systems functionalities using the XML format along with playing and recording functionalities. The editor was thoroughly evaluated: a usability evaluation was conducted with 9 participants, the designed metaphor-based patterns were analyzed for insights on cross-device design and finally the editor was tested with several devices. TactiPEd was successfully and easily used with little training and enabled users to design patterns in little time. The resulting patterns shared common characteristics across the devices for a given metaphor.",
isbn="978-3-642-40480-1"
}

@article{Israr:2016:SHI:2929484.2970273,
 author = {Israr, Ali and Zhao, Siyan and McIntosh, Kyna and Schwemler, Zachary and Fritz, Adam and Mars, John and Bedford, Job and Frisson, Christian and Huerta, Ivan and Kosek, Maggie and Koniaris, Babis and Mitchell, Kenny},
 title = {Stereohaptics: A Haptic Interaction Toolkit for Tangible Virtual Experiences},
 journal = {In proceedings of ACM SIGGRAPH 2016 Studio},
 series = {SIGGRAPH '16},
 year = {2016},
 isbn = {978-1-4503-4373-2},
 location = {Anaheim, California},
 pages = {13:1--13:57},
 articleno = {13},
 numpages = {57},
 memo = {http://doi.acm.org/10.1145/2929484.2970273},
 memo = {10.1145/2929484.2970273},
 acmid = {2970273},
}

@article{posVibEditor,
author={J. {Ryu} and S. {Choi}},
journal={In Proceedings of IEEE International Workshop on Haptic Audio visual Environments and Games},
title={posVibEditor: Graphical authoring tool of vibrotactile patterns},
year={2008},
volume={},
number={},
pages={120-125},
keywords={graphical user interfaces;haptic interfaces;posVibEditor;graphical authoring tool;vibrotactile patterns;vibration motors;multi-channel timeline interface;Haptic interfaces;Piezoelectric actuators;Virtual reality;XML;Testing;Feedback;Humans;Graphical user interfaces;Conferences;Computer science;Vibrotactile pattern;Vibration authoring;Mobile device},
doi={10.1109/HAVE.2008.4685310},
ISSN={},
month={Oct},}

@article{6775509,
author={C. {Swindells} and S. {Pietarinen} and A. {Viitanen}},
journal={In Proceedings of IEEE Haptics Symposium},
title={Medium fidelity rapid prototyping of vibrotactile haptic, audio and video effects},
year={2014},
volume={},
number={},
pages={515-521},
keywords={audio user interfaces;haptic interfaces;human computer interaction;software architecture;software prototyping;medium-fidelity rapid prototyping;vibrotactile haptic effects;audio effects;video effects;Vibrotactile feedback;audio feedback;video feedback;ViviTouch Studio;multimodal rapid prototyping architecture process;operating systems;A/B comparisons;eccentric rotating masses;linear resonant actuators;piezoelectric elements;voice coils;electroactive polymers;Haptic interfaces;Actuators;Prototypes;Media;Games;Containers;Streaming media;Icon;prototype;vibrotactile;multimedia;haptic design tool},
doi={10.1109/HAPTICS.2014.6775509},
ISSN={2324-7355},
month={Feb},}



@article{DBLP:journals/corr/IsolaZZE16,
author={P. Isola and J. Y. Zhu and T. Zhou and A. A. Efros},
journal={In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition},
title={Image-to-Image Translation with Conditional Adversarial Networks},
year={2017},
volume={},
number={},
pages={5967-5976},
keywords={image colour analysis;image reconstruction;learning (artificial intelligence);social networking (online);user interfaces;colorizing images;conditional adversarial networks;edge maps;image-to-image translation;label maps;loss function;mapping functions;Force;Gallium nitride;Generators;Image edge detection;Image resolution;Training},
doi={10.1109/CVPR.2017.632},
ISSN={1063-6919},
month={July},}


@article{Ledig2016,
author={C. Ledig and L. Theis and F. Huszár and J. Caballero and A. Cunningham and A. Acosta and A. Aitken and A. Tejani and J. Totz and Z. Wang and W. Shi},
journal={In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition},
title={Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network},
year={2017},
volume={},
number={},
pages={105-114},
keywords={feedforward neural nets;image reconstruction;image resolution;image sampling;image texture;realistic images;SRGAN;adversarial loss;content loss;deep residual network;deeper convolutional neural networks;discriminator network;generative adversarial network;heavily downsampled images;high-resolution images;mean squared reconstruction error;natural image manifold;objective function;perceptual loss function;perceptual similarity;photo-realistic natural images;photo-realistic single image super-resolution;photo-realistic textures;signal-to-noise ratios;super-resolution methods;upscaling factors;Gallium nitride;Image reconstruction;Image resolution;Manifolds;Network architecture;Signal resolution;Training},
doi={10.1109/CVPR.2017.19},
ISSN={1063-6919},
month={July},}


@article{Goodfellow2014,
abstract = {We propose a new framework for estimating generative models via an adversar- ial process; in which we simultaneously train two models: a generative model G that captures the data distribution; and a discriminative model D that estimates the probability that a sample came from the training data rather thanG. The train- ing procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D; a unique solution exists; with G recovering the training data distribution andD equal to 1 2 everywhere. In the case where G andD are defined by multilayer perceptrons; the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference net- works during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples. 1},
year = {2014},
archivePrefix = {arXiv},
arxivId = {arXiv:1406.2661v1},
author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
memo = {10.1017/CBO9781139058452},
eprint = {arXiv:1406.2661v1},
isbn = {1406.2661},
issn = {10495258},
journal = {In Proceedings of Advances in Neural Information Processing Systems},
pages = {2672--2680},
pmid = {1000183096},
title = {{Generative Adversarial Nets}},
memo = {http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf},
}


@article{Culbertson2014,
abstract = {Texture gives real objects an important perceptual dimension that is largely missing from virtual haptic interactions due to limitations of standard modeling and rendering approaches. This paper presents a set of methods for creating a haptic texture...},
author = {Culbertson, Heather and Unwin, Juliette and Kuchenbecker, Katherine J.},
doi = {10.1109/TOH.2014.2316797},
issn = {19391412},
journal = {IEEE Transactions on Haptics},
keywords = {Data-driven modeling,Haptic texture rendering,High-frequency vibrations,Tablet computers,Virtual reality},
number = {3},
pages = {381--393},
pmid = {25248220},
title = {{Modeling and rendering realistic textures from unconstrained tool-surface interactions}},
volume = {7},
year = {2014}
}

@inbook{Nakatani,
title = "Techtile workshop for creating haptic content",
abstract = "In recent times, haptic technology has advanced to the point where it can be used to manipulate tactile perception. Although haptics research is very popular in academia, the relevant technologies have not yet been implemented to devices that are commonly used, except for small electronic devices. In this chapter, we propose a basic haptic device called the “TECHTILE toolkit” that can design haptic content. We conducted a usability study of our toolkit by hosting more than 50 workshops worldwide that involved professional researchers as well as members of the general public, from children in elementary schools to college students. We classify haptic experiences suggested by participants during the workshops, and also discuss potential haptic content.",
keywords = "Haptic content, Haptic experience, TECHTILE, Vibratory stimuli",
author = "Masashi Nakatani and Yasuaki Kakehi and Kouta Minamizawa and Soichiro Mihara and Susumu Tachi",
year = "2016",
month = "1",
day = "1",
doi = "10.1007/978-4-431-55772-2_12",
language = "English",
isbn = "9784431557715",
pages = "185--200",
booktitle = "Pervasive Haptics: Science, Design, and Application",
publisher = "Springer Japan",
}

@article{Macaron,
author={O. S. {Schneider} and K. E. {MacLean}},
journal={In Proceedings of IEEE Haptics Symposium},
title={Studying design process and example use with Macaron, a web-based vibrotactile effect editor},
year={2016},
volume={},
number={},
pages={52-58},
keywords={haptic interfaces;Internet;learning (artificial intelligence);design process;Macaron;Web-based vibrotactile effect editor;haptic medium;VT effects;learning method;Libraries;Animation;Haptic interfaces;Visualization;Media;Time-frequency analysis},
memo={10.1109/HAPTICS.2016.7463155},
ISSN={2324-7355},
month={April},}


@article{Reed2016,
abstract = {Automatic synthesis of realistic images from text would be interesting and useful, but current AI systems are still far from this goal. However, in recent years generic and powerful recurrent neu-ral network architectures have been developed to learn discriminative text feature representa-tions. Meanwhile, deep convolutional generative adversarial networks (GANs) have begun to gen-erate highly compelling images of specific cat-egories, such as faces, album covers, and room interiors. In this work, we develop a novel deep architecture and GAN formulation to effectively bridge these advances in text and image model-ing, translating visual concepts from characters to pixels. We demonstrate the capability of our model to generate plausible images of birds and flowers from detailed text descriptions.},
archivePrefix = {arXiv},
arxivId = {1605.05396},
author = {Reed, Scott and Akata, Zeynep and Yan, Xinchen and Logeswaran, Lajanugen and Schiele, Bernt and Lee, Honglak},
doi = {10.1017/CBO9781107415324.004},
eprint = {1605.05396},
isbn = {9781510829008},
issn = {1550-5499},
journal = {In Proceedings of ICML},
pages = {1060--1069},
pmid = {25246403},
title = {{Generative Adversarial Text to Image Synthesis}},
year = {2016}
}


@article{Chen2017,
abstract = {Cross-modal audio-visual perception has been a long-lasting topic in psychology and neurology, and various studies have discovered strong correlations in human perception of auditory and visual stimuli. Despite works in computational multimodal modeling, the problem of cross-modal audio-visual generation has not been systematically studied in the literature. In this paper, we make the first attempt to solve this cross-modal generation problem leveraging the power of deep generative adversarial training. Specifically, we use conditional generative adversarial networks to achieve cross-modal audio-visual generation of musical performances. We explore different encoding methods for audio and visual signals, and work on two scenarios: instrument-oriented generation and pose-oriented generation. Being the first to explore this new problem, we compose two new datasets with pairs of images and sounds of musical performances of different instruments. Our experiments using both classification and human evaluations demonstrate that our model has the ability to generate one modality, i.e., audio/visual, from the other modality, i.e., visual/audio, to a good extent. Our experiments on various design choices along with the datasets will facilitate future research in this new problem space.},
archivePrefix = {arXiv},
arxivId = {1704.08292},
author = {Chen, Lele and Srivastava, Sudhanshu and Duan, Zhiyao and Xu, Chenliang},
memo  = {1704.08292},
title = {{Deep Cross-Modal Audio-Visual Generation}},
memo = {http://arxiv.org/abs/1704.08292},
year = {2017},
journal = {CoRR}
}


@article{vmodel,
author = {Forsberg, Kevin and Mooz, Harold},
title = {The Relationship of System Engineering to the Project Cycle},
journal = {In Proceedings of INCOSE International Symposium},
volume = {1},
number = {1},
pages = {57-65},
memo = {10.1002/j.2334-5837.1991.tb01484.x},
memo = {https://onlinelibrary.wiley.com/doi/abs/10.1002/j.2334-5837.1991.tb01484.x},
memo = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/j.2334-5837.1991.tb01484.x},
year = {1991}
}

@article{SCHNEIDER20175,
title = "Haptic experience design: What hapticians do and where they need help",
journal = "International Journal of Human-Computer Studies",
volume = "107",
pages = "5 - 21",
year = "2017",
note = "Multisensory Human-Computer Interaction",
issn = "1071-5819",
memo = "https://doi.org/10.1016/j.ijhcs.2017.04.004",
memo = "http://www.sciencedirect.com/science/article/pii/S1071581917300605",
author = "Oliver Schneider and Karon MacLean and Colin Swindells and Kellogg Booth",
keywords = "User experience, Design, Haptics, Interview, Grounded theory",
abstract = "From simple vibrations to roles in complex multisensory systems, haptic technology is often a critical, expected component of user experience ‚Äì one face of the rapid progression towards blended physical-digital interfaces. Haptic experience design, which is woven together with other multisensory design efforts, interfaces is now becoming part of many designers' jobs. We can expect it to present unique challenges, and yet we know almost nothing of what it looks like ‚Äúin the wild‚Äù due to the field's relative youth, its technical complexity, the multisensory interactions between haptics, sight, and sound, and the difficulty of accessing practitioners in professional and proprietary environments. In this paper, we analyze interviews with six professional haptic designers to document and articulate haptic experience design by observing designers' goals and processes and finding themes at three levels of scope: the multisensory nature of haptic experiences, a map of the collaborative ecosystem, and the cultural context of haptics. Our findings are augmented by feedback obtained in a recent design workshop at an international haptics conference. We find that haptic designers follow a familiar design process, but face specific challenges when working with haptics. We capture and summarize these challenges, make concrete recommendations to conquer them, and present a vision for the future of haptic experience design."
}


@article{Griffin1984,
abstract = {In this paper, we present an algorithm to estimate a signal from its modified short-time Fourier transform (STFT). This algorithm is computationally simple and is obtained by minimizing the mean squared error between the STFT of the estimated signal and the modified STFT. Using this algorithm, we also develop an iterative algorithm to estimate a signal from its modified STFT magnitude. The iterative algorithm is shown to decrease, in each iteration, the mean squared error between the STFT magnitude of the estimated signal and the modified STFT magnitude. The major computation involved in the iterative algorithm is the discrete Fourier transform (DFT) computation, and the algorithm appears to be real-time implementable with current hardware technology. The algorithm developed in this paper has been applied to the time-scale modification of speech. The resulting system generates very high-quality speech, and appears to be better in performancc than any existing metho},
author = {Griffin, D.},
memo = {10.1109/TASSP.1984.1164317},
isbn = {0096-3518 VO - 32},
issn = {0096-3518},
journal = {IEEE Transactions on Acoustics, Speech, and Signal Processing},
keywords = {iterative,phase,reconstruction},
number = {2},
pages = {236--243},
title = {{Signal estimation from modified short-time Fourier transform}},
memo = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1164317},
volume = {32},
year = {1984}
}


@article{Jin2017,
abstract = {Automatic generation of facial images has been well studied after the Generative Adversarial Network (GAN) came out. There exists some attempts applying the GAN model to the problem of generating facial images of anime characters, but none of the existing work gives a promising result. In this work, we explore the training of GAN models specialized on an anime facial image dataset. We address the issue from both the data and the model aspect, by collecting a more clean, well-suited dataset and leverage proper, empirical application of DRAGAN. With quantitative analysis and case studies we demonstrate that our efforts lead to a stable and high-quality model. Moreover, to assist people with anime character design, we build a website (http://make.girls.moe) with our pre-trained model available online, which makes the model easily accessible to general public.},
journal = {CoRR},
archivePrefix = {arXiv},
arxivId = {1708.05509},
author = {Jin, Yanghua and Zhang, Jiakai and Li, Minjun and Tian, Yingtao and Zhu, Huachun and Fang, Zhihao},
eprint = {1708.05509},
file = {:Users/Ujitoko/Library/Application Support/Mendeley Desktop/Downloaded/Jin et al. - 2017 - Towards the Automatic Anime Characters Creation with Generative Adversarial Networks.pdf:pdf},
title = {{Towards the Automatic Anime Characters Creation with Generative Adversarial Networks}},
memo = {http://arxiv.org/abs/1708.05509},
year = {2017}
}

@article{Kodali2017,
abstract = {We analyze convergence of GANs through the lens of online learning and game theory, to understand what makes it hard to achieve consistent stable training in practice. We identify that the underlying game here can be ill-posed and poorly conditioned, and propose a simple regularization scheme based on local perturbations of the input data to address these issues. Currently, the methods that improve stability either impose additional computational costs or require the usage of specific architectures/modeling objectives. Further, we show that WGAN-GP, which is the state-of-the-art stable training procedure, is similar to LS-GAN, does not follow from KR-duality and can be too restrictive in general. In contrast, our proposed algorithm is fast, simple to implement and achieves competitive performance in a stable fashion across a variety of architectures and objective functions with minimal hyperparameter tuning. We show significant improvements over WGAN-GP across these conditions.},
archivePrefix = {arXiv},
journal = {CoRR},
arxivId = {1705.07215},
author = {Kodali, Naveen and Abernethy, Jacob and Hays, James and Kira, Zsolt},
eprint = {1705.07215},
file = {:Users/Ujitoko/Library/Application Support/Mendeley Desktop/Downloaded/Kodali et al. - 2017 - On Convergence and Stability of GANs.pdf:pdf},
title = {{On Convergence and Stability of GANs}},
memo = {http://arxiv.org/abs/1705.07215},
year = {2017}
}

@article{Odena2016,
  title = 	 {Conditional Image Synthesis with Auxiliary Classifier {GAN}s},
  author = 	 {Augustus Odena and Christopher Olah and Jonathon Shlens},
  journal = 	 {In Proceedings of the 34th International Conference on Machine Learning},
  pages = 	 {2642--2651},
  year = 	 {2017},
  editor = 	 {Doina Precup and Yee Whye Teh},
  volume = 	 {70},
  series = 	 {Proceedings of Machine Learning Research},
  publisher = 	 {PMLR},
  memo = 	 {http://proceedings.mlr.press/v70/odena17a/odena17a.pdf},
  memo = 	 {http://proceedings.mlr.press/v70/odena17a.html},
  abstract = 	 {In this paper we introduce new methods for the improved training of generative adversarial networks (GANs) for image synthesis. We construct a variant of GANs employing label conditioning that results in $128\times 128$ resolution image samples exhibiting global coherence. We expand on previous work for image quality assessment to provide two new analyses for assessing the discriminability and diversity of samples from class-conditional image synthesis models. These analyses demonstrate that high resolution samples provide class information not present in low resolution samples. Across 1000 ImageNet classes, $128\times 128$ samples are more than twice as discriminable as artificially resized $32\times 32$ samples. In addition, 84.7\% of the classes have samples exhibiting diversity comparable to real ImageNet data.}
}

@Misc{haptic_reactor,
author = {},
title = {Haptic Reactor},
note = "\url{https://www.alps.com/prod/info/E/HTML/Haptic/}",
}

@article{Lee1991,
abstract = {A visual analogue scale to evaluate fatigue severity (VAS-F) was developed and tested in a sample of 75 healthy individuals and a sample of 57 patients undergoing medical evaluation for sleep disorders. The scale consists of 18 items related to fatigue and energy, has simple instructions, and is completed with minimal time and effort. The VAS-F compares favorably with the Stanford Sleepiness Scale and the Profile of Mood States, and its internal consistency reliabilities are high. Healthy subjects demonstrated significant differences between their evening and morning scores on the VAS-F, while sleep-disordered patients did not. {\textcopyright} 1991.},
author = {Lee, Kathryn A. and Hicks, Gregory and Nino-Murcia, German},
doi = {10.1016/0165-1781(91)90027-M},
isbn = {0165-1781},
issn = {01651781},
journal = {Psychiatry Research},
keywords = {Fatigue,energy,sleep disorders,visual analogue scales},
number = {3},
pages = {291--298},
pmid = {2062970},
title = {{Validity and reliability of a scale to assess fatigue}},
volume = {36},
year = {1991}
}


@Article{Bensma_pacinian,
author="Bensma{\"i}a, Sliman
and Hollins, Mark",
title="Pacinian representations of fine surface texture",
journal="Perception {\&} Psychophysics",
year="2005",
memo="Jul",
day="01",
volume="67",
number="5",
pages="842--854",
abstract="Subjects were presented with pairs of finely textured stimuli and were instructed to rate their dissimilarity, using free magnitude estimation. The subjects also rated the stimuli along each of four textural continua: roughness, hardness, stickiness, and warmth. In subsequent experimental sessions, we used a Hall effect transducer to measure the vibrations produced in the subjects' fingertip skin as the stimuli were scanned across it. We wished to assess the extent to which the perceptual dissimilarity of the textures could be explained in terms of the perceptual dissimilarity of the vibrations they elicited in the skin. To that end, we invoked a model characterizing the Pacinian representation of a vibratory stimulus. From the model, we computed the difference in the vibratory representations of the two stimuli in each pair. We found that the bulk of the variance in perceived dissimilarity of the textures was accounted for by differences in the Pacinian representations of the vibrations they produced. Our results further suggested that the textural information conveyed by the Pacinian system concerns surface roughness and, possibly, stickiness.",
issn="1532-5962",
memo="10.3758/BF03193537",
memo="https://doi.org/10.3758/BF03193537"
}

@Article{Bensma_vibro,
author="Bensma{\"I}a, Sliman
and Hollins, Mark
and Yau, Jeffrey",
title="Vibrotactile intensity and frequency information in the Pacinian system: A psychophysical model",
journal="Perception {\&} Psychophysics",
year="2005",
month="Jul",
day="01",
volume="67",
number="5",
pages="828--841",
abstract="The objective of the study was to characterize the Pacinian representation of stimulus waveform. Subjects were presented with pairs of high-frequency vibrotactile stimuli that varied in intensity and/or frequency content and madesame---different judgments under conditions of low-frequency adaptation designed to minimize the contribution of the RA system. We wished to infer the nature of the information conveyed by the Pacinian system about the stimuli from measured sensitivity (d{\textasciiacutex}) to stimulus differences. We first tested the hypothesis that the Pacinian system conveys only intensive information about vibratory stimuli and found that intensive cues could not account for much of the variance in the discrimination data. We then proposed a model characterizing the Pacinian-mediated representation of an arbitrary stimulus as a pattern of activation in a set of frequency-tuned minichannels. The model was shown to predict the discriminability of the stimulus pairs presented in the psychophysical experiments. Furthermore, the model parameters, optimized to fit the discrimination data, were compatible with analogous values obtained in other experimental contexts. One of the assumptions underlying the model is that information about individual spectral components is conveyed in parallel and quasi-independently. By simulating the response of a population of Pacinian afferents to a polyharmonic stimulus, we demonstrated that such a population can simultaneously convey information about multiple frequency components, despite having a homogeneous spectral profile.",
issn="1532-5962",
memo="10.3758/BF03193536",
memo="https://doi.org/10.3758/BF03193536"
}
